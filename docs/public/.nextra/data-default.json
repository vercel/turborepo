{
  "/": { "title": "Home", "data": { "": "" } },
  "/blog": { "title": "All Posts", "data": { "": "" } },
  "/blog/joining-vercel": {
    "title": "Joining Vercel",
    "data": {
      "": "Turborepo has been acquired by Vercel and the Turborepo CLI is now open-source! Also, Turborepo now provides zero-config remote caching throughÂ Vercel!beta.turborepo.com and its remote caching service will be shut down on January 15th, 2022 and older versions of the turbo CLI will not be installable. Learn more about how to upgrade your CLI and migrate to Vercel here.This is a milestone moment for the project and for all of you who have supported and adopted Turborepo. With Vercel's infrastructure and team backing, I'll expand on the capabilities of Turborepo and build out a team focused on improving their world-class build system. I can't wait to bring you along for this next chapter.Join me this Friday, December 10 at 4:00 p.m. ET | 9:00 p.m GMT for a livestream Q&A with Vercel's Head of Developer Relations, Lee Robinson. We'll go over what's in store for Turborepo and Vercel as we work toward improving the developer experience together.This is just the beginning. We're about to embark on a world of even faster builds, even more flexibility, and even better workflows. Thanks for joining us on this amazing journey."
    }
  },
  "/blog/saml-sso-now-available": {
    "title": "SAML SSO now available",
    "data": {
      "": "Thanks to our friends over at WorkOS, in addition to GitHub, Gitlab, and Passwordless auth, Turborepo.com now supports Single Sign-on (SSO) from the following SAML providers for enterprise customers:\nAD FS SAML\nAuth0 SAML\nAzure AD SAML\nCyberArk SAML\nGeneric SAML\nG Suite OAuth\nG Suite SAML\nJumpCloud SAML\nMicrosoft OAuth\nOkta SAML\nOneLogin SAML\nOpenID Connect\nPingFederate SAML\nPingOne SAML\nShibboleth\nVMWare SAML\n\nWe also support SCIM (a.k.a. \"Directory Sync\") via:\nAzure AD SCIM\nBambooHR\nG Suite\nGusto\nHibob\nOkta SCIM v1.1\nOkta SCIM v2.0\nRippling\nSCIM v1.1\nSCIM v2.0\nWorkday\n\nIf you're team in interested in activating SAML SSO, please contact us sales@turborepo.com.",
      "whats-next#What's next?": "We take security extremely seriously. And while SSO is certainly a must in 2021, we are also currently undergoing a third-party SOC 2 Type 2 examination as well. Last but not least, we are adding biometric/U2F access controls and audit logs this fall. Stay tuned for updates."
    }
  },
  "/blog/turbo-0-4-0": {
    "title": "Turborepo v0.4.0",
    "data": {
      "": "I'm excited to announce the release of Turborepo v0.4.0!\n10x faster: turbo has been rewritten from the ground up in Go to make it even more blazing fast\nSmarter hashing: Improved hashing algorithm now considers resolved dependencies instead of just the contents of the entire root lockfile\nPartial lockfiles / sparse installs: Generate a pruned subset of your root lockfile and monorepo that includes only the necessary packages needed for a given target\nFine-grained scheduling: Improved task orchestration and options via pipeline configuration\nBetter cache control: You can now specify cache outputs on a per-task basis",
      "rewritten-in-go#Rewritten in Go": "Although I initially prototyped turbo in TypeScript, it became clear that certain items on the roadmap would require better performance. After around a month or so of work, I'm excited to finally release Go version of the turbo CLI. Not only does it boot in a milliseconds, but the new Go implementation is somewhere between 10x and 100x faster at hashing than the Node.js implementation. With this new foundation (and some features you're about to read about), Turborepo can now scale to intergalactic sized projects while remaining blazing fast all thanks to Go's awesome concurrency controls.",
      "better-hashing#Better Hashing": "Not only is hashing faster in v0.4.0, but also a lot smarter.The major change is that turbo no longer includes the hash of the contents of the root lockfile in its hasher (the algorithm responsible for determining if a given task exists in the cache or needs to be executed). Instead, turbo now hashes the set of the resolved versions of a package's dependencies and devDependencies based on the root lockfile.The old behavior would explode the cache whenever the root lockfile changed in any way. With this new behavior, changing the lockfile will only bust the cache for those package's impacted by the added/changed/removed dependencies. While this sounds complicated, again all it means is that when you install/remove/update dependencies from NPM, only those packages that are actually impacted by the changes will need to be rebuilt.",
      "experimental-pruned-workspaces#Experimental: Pruned Workspaces": "One of our biggest customer pain points/requests has been improving Docker build times when working with large Yarn Workspaces (or really any workspace implementation). The core issue is that workspaces' best feature--reducing your monorepo to a single lockfile--is also its worst when it comes to Docker layer caching.To help articulate the problem and how turbo now solves it, let's look at an example.Say we have a monorepo with Yarn workspaces that includes a set of packages called frontend, admin, ui, and backend. Let's also assume that frontend and admin are Next.js applications that both depend on the same internal React component library package ui. Now let's also say that backend contains an Express TypeScript REST API that doesn't really share much code with any other part of our monorepo.Here's what the Dockerfile for the frontend Next.js app might look like:\nFROM node:alpine AS base\nRUN apk update\nWORKDIR /app\n\n# Add lockfile and package.jsons\nFROM base AS builder\nCOPY *.json yarn.lock ./\nCOPY packages/ui/*.json ./packages/ui/\nCOPY packages/frontend/*.json ./packages/frontend/\nRUN yarn install\n\n# Copy source files\nCOPY packages/ui/ ./packages/ui/\nCOPY packages/frontend/ ./packages/frontend/\n\n# Build\nRUN yarn --cwd=packages/ui/ build\nRUN yarn --cwd=packages/frontend/ build\n\n# Start the Frontend Next.js application\nEXPOSE 3000\nRUN ['yarn', '--cwd', 'packages/frontend', 'start']\nWhile this works, there are some things that could be a lot better:\nYou manually COPY in the internal packages and files needed to build the target app and need to remember which need to be built first.\nYou COPY the root yarn.lock lockfile into the correct position very early in the Dockerfile, but this lockfile is the lockfile for the entire monorepo.\n\nThis last issue is especially painful as your monorepo gets larger and larger because any change to this lockfile triggers a nearly full rebuild regardless of whether or not the app is actually impacted by the new/changed dependencies.....until now.With the all new turbo prune command, you can now fix this nightmare by deterministically generating a sparse/partial monorepo with a pruned lockfile for a target package--without installing your node_modules.Let's look at how to use turbo prune inside of Docker.\nFROM node:alpine AS base\nRUN apk update && apk add git\n\n## Globally install turbo\nRUN npm i -g turbo\n\n# Prune the workspace for the `frontend` app\nFROM base as pruner\nCOPY .git ./.git\nCOPY . .\nRUN turbo prune --scope=frontend\n\n# Add pruned lockfile and package.json's of the pruned subworkspace\nFROM pruner AS installer\nCOPY --from=builder /app/out/json/ .\nCOPY --from=builder /app/out/yarn.lock ./yarn.lock\n# Install only the deps needed to build the target\nRUN yarn install\n\n# Copy source code of pruned subworkspace and build\nFROM installer as builder\nWORKDIR /app\nCOPY --from=pruner .git ./.git\nCOPY --from=installer /app/ .\nCOPY --from=builder /app/out/full/ .\nRUN turbo run build --scope=frontend\n\n# Start the app\nFROM builder as runner\nEXPOSE 3000\nRUN ['yarn', '--cwd', 'packages/frontend', 'start']\nSo what exactly is the output of the turbo prune? A folder called out with the following inside of it:\nA folder json with the pruned workspace's package.jsons\nA folder full with the pruned workspace's full source code, but only including the internal packages that are needed to build the target\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the packages in the pruned workspace.\n\nThanks to the above, Docker can now be set up to only rebuild each application when there is a real reason to do so. So frontend will only rebuild when its source or dependencies (either internal or from NPM) have actually changed. Same same for admin and backend. Changes to ui, either to its source code or dependencies, will trigger rebuilds of both frontend and admin, but not backend.While this example seems trivial, just imagine if each app takes up to 20 minutes to build and deploy. These savings really start to add up quickly, especially on large teams.",
      "pipelines#Pipelines": "To give you even more control over your Turborepo, we've added pipeline to turbo's configuration. This new field in lets you specify how the NPM scripts in your monorepo relate to each other as well as some additional per-task options. turbo then uses this information to optimally schedule your tasks in your monorepo, collapsing waterfalls that would otherwise exist.Here's how it works:\n// <root>/package.json\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// This `^` tells turbo that this pipeline target relies on a topological target being completed.\n// In english, this reads as: \"this package's `build` command depends on its dependencies' or\n// devDependencies' `build` command being completed\"\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n//  `dependsOn` without `^` can be used to express the relationships between tasks at the package level.\n// In English, this reads as: \"this package's `test` command depends on its `lint` and `build` command first being completed\"\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"lint\": {},\n\"dev\": {},\n\n}\n}\n}\nThe above config would then be interpreted by turbo to optimally schedule execution.What's that actually mean? In the past (like Lerna and Nx), turbo could only run tasks in topological order. With the addition of pipelines, turbo now constructs a topological \"action\" graph in addition to the actual dependency graph which it uses to determine the order in which tasks should be executed with maximum concurrency. The end result is that you no longer waste idle CPU time waiting around for stuff to finish (i.e. no more waterfalls).",
      "improved-cache-control#Improved Cache Control": "Thanks to pipeline, we now have a great place to open up turbo's cache behavior on a per-task basis.Building on the example from above, you can now set cache output conventions across your entire monorepo like so:\n// <root>/package.json\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// Cache anything in dist or .next directories emitted by a `build` command\n\"outputs\": [\"dist/**\", \".next/**\"]\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// Cache the test coverage report\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"dev\": {\n// Never cache the `dev` command\n\"cache\": false\n},\n\"lint\": {},\n}\n}\n}\nNote: Right now, pipeline exists at the project level,\nbut in later releases these will be overridable on per-package basis.",
      "whats-next#What's Next?": "I know this was a lot, but there's even more to come. Here's what's up next on the Turborepo roadmap.\nA landing page!\nRemote caching w/ @turborepo/server\nBuild scans, telemetry, and metrics and dependency and task graph visualization\nDesktop Console UI\nIntelligent watch mode\nOfficial build rules for TypeScript, React, Jest, Node.js, Docker, Kubernetes, and more",
      "credits#Credits": "Iheanyi Ekechukwu for guiding me through the Go ecosystem\nMiguel Oller and the team from Makeswift for iterating on the new prune command"
    }
  },
  "/blog/you-might-not-need-typescript-project-references": {
    "title": "You might not need TypeScript project references",
    "data": {
      "": "If you've worked in a larger TypeScript codebase or monorepo, you are likely familiar with project references. They are indeed fairly powerful.When you reference a project in your tsconfig.json, new things happen:\nImporting modules from a referenced project will instead load its output declaration file (.d.ts)\nIf the referenced project produces an outFile, the output file .d.ts fileâ€™s declarations will be visible in this project\nRunning build mode (tsc -b) will automatically build the referenced project if it hasn't been built but is needed\nBy separating into multiple projects, you can greatly improve the speed of typechecking and compiling, reduce memory usage when using an editor, and improve enforcement of the logical groupings of your program.\n\nSounds awesome! Right?! Well...maybe. Once you add references to your project you now need to continuously update them whenever you add or remove packages. That kinda blows.Well...what if you didn't need to?",
      "internal-typescript-packages#\"Internal\" TypeScript Packages": "As it turns out, you might not even need references or even an interim TypeScript build step with a pattern I am about to show you, which I dub \"internal packages.\"An \"internal package\" is a TypeScript package without a tsconfig.json with both its types and main fields in its package.json pointing to the package's untranspiled entry point (e.g. ./src/index.tsx).\n{\n\"name\": \"@sample/my-internal-package\"\n\"main\": \"./src/index.ts\"\n\"types\": \"./src/index.ts\", // yes, this works!\n\"dependencies\": {\n...\n},\n\"devDependencies\": {\n...\n}\n}\nAs it turns out, the TypeScript Language Server (in VSCode) and Type Checker can treat both a raw .ts or .tsx file as its own valid type declaration. This last sentence is obvious once you read it twice. What isn't so obvious, though, is that you can point the types field directly to raw source code.Once you do this, this package can then be used without project references or a TypeScript build step (either via tsc or esbuild etc) as long as you adhere to 2 rules:\nThe consuming application of an internal package must transpile and typecheck it.\nYou should never publish an internal package to NPM.\n\nAs far as I can tell, this internal package pattern works with all Yarn/NPM/PNPM workspace implementations regardless of whether you are using Turborepo or some other tool. I have personally tested this pattern with several different meta frameworks (see below), but I'm sure that it works with others as well.",
      "nextjs#Next.js": "If you use Next.js, you can satisfy these constraints with the next-transpile-modules plugin which will tell Next.js to run certain dependencies through its Webpack/Babel/TypeScript pipelines.",
      "vite#Vite": "Internal packages just work. No extra config is needed.",
      "react-native#React Native": "If you use Expo and use the expo-yarn-workspaces or @turborepo/adapter-expo package, you can use internal packages as long as you are targeting iOS or Android. When you run Expo for these platforms, all of node_modules are automatically transpiled with Metro. However, if you are targeting Expo for web, internal packages will not work because node_modules are oddly not transpiled for web.I reached out to the Expo team about this inconsistency. They are aware of it. It's a legacy wart I'm told.",
      "the-beauty-of-this-pattern#The beauty of this pattern": "This pattern rocks because it saves you from extra needless or duplicative build steps. It also gives you all the editor benefits of project references, but without any configuration.",
      "caveats#Caveats": "When you use an internal package, it's kind of like telling the consuming application that you have another source directoryâ€”which has pros and cons. As your consuming application(s) grow, adding more internal packages is identical to adding more source code to that consuming application. Thus, when you add more source code, there is more code to transpile/bundle/typecheck...so this can result in slower builds of the consuming application (as there is just more work to do) but potentially faster (and less complicated) overall build time. When/if overall build time begins to suffer, you might decide to convert your larger internal packages back into \"regular\" packages with .d.ts files and with normal TypeScript build steps.As previously mentioned, this pattern actually has very little to do with Turborepo. It's just super duper awesome and I think you should be aware of it. As we are actively working on preset package build rules (i.e. \"builders\") for Turborepo, we'll using the internal package pattern to skip build steps.",
      "speaking-of-long-build-times#Speaking of long build times...": "Shameless plug here. If you are reading this post, and you're struggling with slow build and test times, I'd love to show you how Turborepo can help. I guarantee that Turborepo will cut your monorepo's build time by 50% or more. You can request a live demo right here."
    }
  },
  "/docs/acknowledgments": {
    "title": "acknowledgments",
    "data": {
      "": "Turborepo was originally created by Jared Palmer as a closed-source enterprise software offering. In late 2021, Vercel acquired Turborepo and open sourced the codebase.Today, Turborepo has dedicated full-time team working on it as well as a growing list of open source contributors.",
      "inspiration--prior-art#Inspiration / Prior Art": "At Vercel, we believe deeply in the open source movement and in the power of open collaboration. To that end, it's important to provide meaningful attribution to the projects and people that inspire(d) us and our work.We'd like to make a special shoutout to other build systems, monorepo tools, and prior art:\nBazel - https://bazel.build\nBuck - https://buck.build\nPlease - https://please.build\nPants - https://www.pantsbuild.org\nScoot - https://github.com/twitter/scoot\nTSDX - https://tsdx.io\nLerna - https://lerna.js.org\nLage - https://microsoft.github.io/lage\nBackfill - https://github.com/microsoft/backfill\nBolt - https://github.com/boltpkg/bolt\nRush - https://rushjs.io\nPreconstruct - https://preconstruct.tools\nNx - https://nx.dev\nYarn - https://yarnpkg.com\nNPM - https://www.npmjs.com\nPNPM - https://pnpm.js.org\n\nThroughout the documentation, wherever applicable, we also provide inline callouts and links to the projects and people that have inspired us.",
      "additional-thanks#Additional Thanks": "Additionally, we're grateful to:\nRick Button for donating the turbo package name on NPM\nIheanyi Ekechukwu for helping Jared pick up Golang during the Pandemic!\nKenneth Chau for Lage's Scope and Pipeline API and docs\nMiguel Oller and MakeSwift.com for piloting Turbo\nEric Koslow, Jack Hanford, and Lattice.com for piloting Turbo"
    }
  },
  "/docs/changelog": {
    "title": "Changelog",
    "data": {
      "": "This page is not used. It is just redirected to https://github.com/vercel/turborepo/releases"
    }
  },
  "/docs/faq": {
    "title": "FAQ",
    "data": {
      "": "",
      "do-i-have-to-use-remote-caching-to-use-turborepo#Do I have to use Remote Caching to use Turborepo?": "No. Remote Caching is optional. However, you'll find it very useful to speed up development on a team, speed up builds inside of Docker, and also save space on your own machine.",
      "does-turborepo--remote-caching-store-my-source-code#Does Turborepo / Remote Caching store my source code?": "No. Turborepo does not store source code. Without Remote Caching, no code ever leaves your machineâ€”it will only cache artifacts to local disk.With Turborepo's Remote Caching, you are responsible for configuring cache behavior and should only set up Turborepo to cache compiled artifacts. Please be aware that Turborepo treats all logs as artifacts and so these will be stored along with other cache artifacts.",
      "do-i-have-to-use-vercel-to-use-turborepo#Do I have to use Vercel to use Turborepo?": "No. Turborepo is an open source project and is not tied to any specific hosting provider or Remote Cache provider. The default Remote Cache provider is Vercel, should you opt-in to enable it. However, you can use any other provider that you like as long as they support the same API. There are a several open source community Remote Caches that are compatible with Turborepo.",
      "can-i-use-turborepo-with-a-different-remote-cache-provider-other-than-vercel#Can I use Turborepo with a different Remote Cache provider other than Vercel?": "Yes. As long as the Remote Cache provider you choose supports the same API, you can use Turborepo with it.",
      "does-turborepo-collect-and-personally-identifiable-information#Does Turborepo collect and personally identifiable information?": "Due to the nature of Turborepo's functionality, no personal information is gathered when the open source binary is run locally. All cached artifacts are stored on your machine by default. Further, no log in information or contact details are collected by the turbo CLI, so Turborepo will never have access to any personally identifiable information. Thus, for any data privacy questions and concerns please refer to Turborepo's Privacy Policy.",
      "does-turborepo-collect-and-personally-identifiable-information-when-using-remote-caching#Does Turborepo collect and personally identifiable information when using Remote Caching?": "When Remote Caching is enabled, by default Turbo will utilize your Vercel account to cache artifacts in the cloud. Thus, for any data privacy questions and concerns, please refer to Turborepo's Privacy Policy and Vercel's Privacy Policy. If you use a different Remote Cache provider, please refer to the provider's privacy policy."
    }
  },
  "/docs/getting-started": {
    "title": "Getting Started",
    "data": {
      "": "",
      "clone-an-example-or-starter-monorepo#Clone an example or starter monorepo": "If you're starting a brand new monorepo, you can get started with a single command.\nnpx create-turbo@latest\nFollow the prompts to bootstrap a brand new Turborepo.To see more examples and starters, have a look at the examples directory on GitHub",
      "add-turborepo-to-your-existing-monorepo#Add Turborepo to your existing monorepo": "Turborepo was designed to be incrementally adopted. Adding it to an existing monorepo takes only a few minutes.Turborepo works with Yarn v1, NPM, and PNPM workspaces. The turbo CLI works on the following operating systems.\nmacOS darwin 64-bit (Intel), ARM 64-bit (Apple Silicon)\nLinux 32-bit, 64-bit, ARM, ARM 64-bit, MIPS 64-bit Little Endian, PowerPC 64-bit Little Endian, IBM Z 64-bit Big Endian\nWindows 32-bit, 64-bit, ARM 64-bit\nFreeBSD 64-bit, ARM 64-bit\nNetBSD AMD64\nAndroid ARM 64-bit",
      "install-turbo#Install turbo": "Add turbo as a development dependency in the root of your project.",
      "yarn#Yarn": "yarn add turbo -DW",
      "npm#NPM": "npm install turbo -D",
      "pnpm#PNPM": "pnpm add turbo -DW\nThe turbo package is a little shell that will install the proper @turborepo/* packages.",
      "add-turbo-to-packagejson#Add turbo to package.json": "In your root package.json, add a key turbo. If your git repo's base branch is NOT origin/master then you need to specify a baseBranch too (for example, ours is set to origin/main).\n{\n\"turbo\": {\n\"baseBranch\": \"origin/main\"\n}\n}",
      "create-a-pipeline#Create a pipeline": "In your package.json, add the commands you want to \"turbocharge\" to your pipeline.Your pipeline both defines the way in which your NPM package.json scripts relate to each other, and configures cache artifacts for those scripts. These relationships and cache settings are then fanned out and applied to all package tasks across your entire monorepo.\n{\n\"turbo\": {\n\"baseBranch\": \"origin/main\",\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": [\".next/**\"]\n},\n\"test\": {\n\"dependsOn\": [\"^build\"],\n\"outputs\": []\n},\n\"lint\": {\n\"outputs\": []\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}\n}\nIn the above example, the build and test tasks are dependent on their packages dependencies and devDependencies being built first, this is denoted with the ^ prefix.For each script in each workspace's package.json, Turborepo will cache files outputted to dist/** and build/** folders by default if an override isn't added. Using the outputs array allows you to override the default cache folders,\nlike in the example above, where the .next/** folder is selected to be the default cache folder for the build task. Turborepo will automatically record and cache logs to .turbo/turbo-<script>.log for you, so you don't ever need to specify that in the outputs array.Finally, the dev task has its caching disabled using the cache key with a value of false.See the Pipelines documentation for more details on how to configure your pipeline.",
      "edit-gitignore#Edit .gitignore": "Next, add .turbo to your .gitignore file. The CLI uses these folders for logs and certain task outputs.\n+ .turbo\nMake sure that your task artifacts (the files you want to be cached) are also ignored. As a rule, any files/folder that you want cached should be gitignored.\n+ build/**\n+ dist/**\n+ .next/**",
      "ensure-workspaces-are-configured#Ensure workspaces are configured": "If you are moving from another tool to Yarn workspaces, be sure to also specify all workspaces in your package.json. The convention we follow is for applications to go into the /apps folder and packages to go in /packages folders.\n{\n+ \"workspaces\": [\n+    \"packages/*\",\n+    \"apps/*\"\n+  ]\n}\nNow re-run your NPM client's install command just to be sure. You should be good to go now.",
      "run-stuff#Run stuff!": "To build with your freshly installed turbo, type the following:",
      "yarn-1#Yarn": "yarn turbo run build\nNow run it again. Depending on your monorepo setup, some stuff might already be caching properly. If not, no worries! In the next sections, we'll discuss how turbo works, how scope works, and then how to get caching working after that.",
      "setup-remote-caching-#Setup Remote Caching ": "A major key ðŸ”‘ to Turborepo's speed is that it is both lazy and efficientâ€”it does the least amount of work possible and it tries to never redo work that's already been done before.\nAt the moment, Turborepo caches your tasks on your local filesystem (i.e. \"single-player mode,\" if you will). However, what if there was a way to take advantage of the computational work done by your teammates or your CI (i.e. \"co-op multiplayer mode\")? What if there was a way to teleport and share a single cache across machines? Almost like a \"Dropbox\" for your Turborepo cache.\nRemote Caching has entered the chat.\nTurborepo can use a technique known as Remote Caching to share cache artifacts across machines for an additional speed boost.\nRemote Caching is a powerful feature of Turborepo, but with great power comes great responsibility. Make sure you are caching correctly first and double check handling of environment variables. Please also remember Turborepo treats logs as artifacts, so be aware of what you are printing to the console.",
      "link-your-turborepo-to-your-remote-cache#Link Your Turborepo to Your Remote Cache": "As part of Turborepo's initial public launch, Vercel is offering free remote caching on all accounts with zero-configuration needed.",
      "using-remote-caching-for-local-development#Using Remote Caching for Local development": "If you want to link your local turborepo to your Remote Cache you do so by first authenticating the Turborepo CLI with your Vercel account:\nnpx turbo login\nNext, you can link your turborepo to your remote cache by running the following command:\nnpx turbo link\nOnce enabled, make some changes to a package or application you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache. To verify that this worked, delete your local Turborepo cache:\nrm -rf ./node_modules/.cache/turbo\nNow run the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you."
    }
  },
  "/docs/glossary": {
    "title": "Glossary",
    "data": {
      "": "A running list of computer science, mathematical, graph theory, and build system terms and jargon used in the documentation.",
      "topological-order#Topological Order": "A fancy term for \"dependency first\" order. So if A depends on B and B depends on C, then topological order is C, B, A.In computer science, a topological sort or topological ordering of a directed graph is a linear ordering of its vertices such that for every directed edge uv from vertex u to vertex v, u comes before v in the ordering.\nA topological ordering is possible if and only if the graph has no directed cycles, that is, if it is a directed acyclic graph (DAG). Any DAG has at least one topological ordering, and algorithms are known for constructing a topological ordering of any DAG in linear time.Learn More",
      "directed-acyclic-graph-dag#Directed Acyclic Graph (DAG)": "In mathematics, particularly graph theory, and computer science, a directed acyclic graph is a directed graph with no directed cycles. That is, it consists of vertices and edges (also called arcs), with each edge directed from one vertex to another, such that following those directions will never form a closed loop. A directed graph is a DAG if and only if it can be topologically ordered, by arranging the vertices as a linear ordering that is consistent with all edge directions. DAGs have numerous scientific and computational applications, ranging from biology (evolution, family trees, epidemiology) to sociology (citation networks) to computation (scheduling).Learn more",
      "hash-function#Hash function": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or hashes.Learn more",
      "remote-caching#Remote Caching": "A remote cache is used by a team of developers and/or a continuous integration (CI) system to share build outputs. If your build is reproducible, the outputs from one machine can be safely reused on another machine, which can make builds significantly faster."
    }
  },
  "/docs": {
    "title": "Introduction",
    "data": {
      "": "Turborepo is a blazing fast build system for JavaScript/TypeScript monorepos: codebases containing multiple\nprojects, often using multiple frameworks, in a single unified\ncode repository.Monorepos have many advantages, but they require appropriate tooling in order to scale. Turborepo provides this tooling and more. It leverages advanced build system ideas and techniques to speed up development, but with a fraction of the configuration and complexity. Instead of wasting countless days worrying about how you're shipping, Turborepo lets you focus on what you're shipping by abstracting all the annoying configuration, scripts, and tooling on your behalf.Last but not least, unlike other build systems, Turborepo is designed to be incrementally adopted, so you can gradually and partially add it to most codebases in a few minutes.",
      "why-turborepo#Why Turborepo?": "Faster, incremental builds: Building once is painful enough, Turborepo will remember what you've built and skip the stuff that's already been computed.\nContent-aware hashing: Turborepo looks at the contents of your files, not timestamps to figure out what needs to be built.\nCloud caching: Share a cloud build cache with your teammates and CI/CD for even faster builds.\nParallel execution: Execute builds using every core at maximum parallelism without wasting idle CPUs.\nZero runtime overhead: Turborepo doesn't interfere with your runtime code or touch your sourcemaps. It does what it does and then gets out of your way.\nTask pipelines: Define the relationships between your tasks and then let Turborepo optimize what to build and when.\nPruned subsets: Speed up PaaS deploys by generating a subset of your monorepo with only what's needed to build a specific target.\nConvention-based config: Reduce complexity through convention. Fan out configuration with just a few lines of JSON.\nProfile in your browser: Generate build profiles and import them in Chrome or Edge to understand which tasks are taking the longest."
    }
  },
  "/docs/upgrading-to-v1": {
    "title": "Upgrading to v1",
    "data": {
      "": "Turborepo has been acquired by Vercel! With this announcement, Vercel is open sourcing the turbo CLI and offering Remote Caching for free on all accounts during the transition period.Existing Turborepo customers should upgrade their turbo CLI to v1.x as soon as possible and migrate to Vercel (instructions below). Earlier versions of turbo CLI prior to 1.x will no longer be maintained going forward. New account creation on beta.turborepo.com has been disabled. The beta.turborepo.com dashboard and remote caching service will be shutdown on January 15th, 2022 and older versions will not be installable.All existing Remote Cache artifacts will also be deleted at this time.Below is a step-by-step migration guide for existing Turborepo users. If you get stuck, please reach out in the community Discord or file an issue on GitHub. Thank you again for your continued support as we begin this awesome new chapter of Turborepo together.",
      "1-cleaning-up#1. Cleaning up": "For good hygiene, ensure you logout of turbo to remove old credentials:\nyarn turbo logout\nIf it exists, also delete the .turbo directory from the root of your monorepo:\nrm -rf .turbo",
      "2-install-the-latest-release-of-turbo#2. Install the latest release of turbo": "Install the latest version version of turbo:\nyarn add turbo -W --dev",
      "3-setup-remote-caching#3. Setup Remote Caching": "As mentioned, Turborepo now provides zero-config Remote Caching through Vercel. Remote Caching is free for all Vercel plans during this transition period. Each Vercel account has a shared Remote Cache. This cache is shared across all environments (Development, Preview, and Production).Important: turborepo.com allowed multiple caches (i.e. projects) per team (denoted through --project flag). With v1.x caching on Vercel, each Vercel account (user or team) has a single shared Remote Cache. If you were actively using multiple turborepo.com projects for your team, please let us know in Discord.Please note that we are not migrating cache artifacts to Vercel. We apologize for the slower builds during your migration as you rehydrate your remote cache on Vercel or custom cache infra.",
      "4-local-development#4. Local Development": "If you were using Remote Caching for local development, upgrading will take a minute or two. To get started, login to the Vercel CLI:\nnpx vercel login\nNow we can set up Remote Caching through Vercel by running:\nnpx turbo link\nFollow the prompts and select the Vercel account (user or team) to wish to connect to.",
      "on-vercel#On Vercel": "If you already used Turborepo and Vercel together, you should remove TURBO_TOKEN, TURBO_TEAM, and TURBO_PROJECT environment variables from all projects. These are now automatically set on your behalf by Vercel.\nRemove the usage of --team, --token, and --project CLI flags in your Vercel project settings and/or package.json scripts.",
      "on-other-cicd#On other CI/CD": "Replace your turborepo.com personal access token with a new Vercel personal access token and update TURBO_TOKEN environment variable or equivalent usage of the --token CLI flag.\nRemove TURBO_PROJECT environment variable and remove all usage of the --project CLI flag. This has been deprecated.\nUpdate the value of the TURBO_TEAM environment variable and --team CLI flag to be your Vercel account slug (i.e. https://vercel.com/<slug>).",
      "getting-help#Getting Help": "If you are having difficulty upgrading please file an issue on GitHub. If you are having difficulty with your remote caching on Vercel, please reach out in Discord."
    }
  },
  "/docs/features/caching": {
    "title": "Caching",
    "data": {
      "": "Unlike other tools you may have used, turbo can cache emitted files and logs of previously run commands. It does this so it can skip work that's already been done, yielding incredible time savings.By default, turbo run considers any files emitted in the dist/** or build/** folders of a package task (defined in that package's package.json scripts object) to be cacheable. In addition, turbo run treats logs (stderr andstdout), which are automatically written to .turbo/run-<command>.log, as a cacheable artifact. By treating logs as artifacts, you can cache just about any command in your Turborepo.",
      "configuring-cache-outputs#Configuring Cache Outputs": "Using pipeline, you can configure cache conventions across your Turborepo.To override the default cache folder behavior, pass an array of globs to a pipeline.<task>.outputs array. Any file that satisfies the glob patterns for a task will be treated as artifact.\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"outputs\": [\"dist/**\", \".next/**\"],\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [], // leave empty to only cache logs\n\"dependsOn\": [\"build\"]\n}\n}\n}\n}\nIf your task does not emit any files (e.g. unit tests with Jest), set outputs to an empty array (i.e. []). Turborepo will automagically cache the logs for you.\nPro Tip for caching ESLint: You can get a cacheable pretty terminal output\n(even for non-errors) by setting TIMING=1 variable before eslint. Learn\nmore over at the ESLint\ndocs\nWith the above pipeline configuration and proper output folders, if you were to run:\n# Run `build` npm script in all packages and apps and cache the output.\nturbo run build test\nAnd open up your node_modules/.cache/turbo, you should see the cached artifacts.",
      "turn-off-caching#Turn off caching": "Sometimes you really don't need or want this cache behavior (such as when you're doing something with live reloading such as next dev or react-scripts start). To entirely disable caching, append --no-cache to any command:\n# Run `dev` npm script in all packages and apps in parallel,\n# but don't cache the output\nturbo run dev --parallel --no-cache\nYou can also always disable caching on a specific task by setting cache to false in your Turborepo pipeline:\n{\n\"turbo\": {\n\"pipeline\": {\n\"dev\": {\n\"cache\": false\n}\n}\n}\n}",
      "alter-caching-based-on-environment-variables-and-files#Alter Caching Based on Environment Variables and Files": "When you use turbo with tools which inline environment variables at build time (e.g. Next.js or Create React App), it is important you tell turbo about it. Otherwise, you could ship a cached artifact with the wrong environment variables!Luckily, you can control turbo's cache fingerprinting (a.k.a. hashing) behavior based on the values of both environment variables and the contents of files:\nIncluding environment variables in a dependsOn in your pipeline definition prefixed by a $ will impact the cache fingerprint on a per-task or per-package-task basis.\nIncluding environment variables in globalDependencies list prefixed by a $ will impact the cache fingerprint of all tasks.\nIncluding files or globs of files in globalDependencies will impact the cache fingerprint of all tasks.\nThe value of any environment variable that includes THASH in its name will impact the cache fingerprint of all tasks.\n\n\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": {\n\"^build\"\n// env vars will impact hashes of all \"build\" tasks\n\"$SOME_ENV_VAR\"\n},\n\"outputs\": [\"dist/**\"]\n},\n\"web#build\": { // override settings for the \"build\" task for the \"web\" app\n\"dependsOn\": [\n\"^build\",\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"$STRIPE_SECRET_KEY\",\n\"$NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"$NEXT_PUBLIC_ANALYTICS_ID\",\n],\n\"outputs\": [\".next/**\"],\n},\n\"docs#build\": { // override settings for the \"build\" task for the \"docs\" app\n\"dependsOn\": [\n\"^build\",\n// env vars that will impact the hash of \"build\" task for only \"web\" app\n\"$STRIPE_SECRET_KEY\",\n\"$NEXT_PUBLIC_STRIPE_PUBLIC_KEY\",\n\"$NEXT_PUBLIC_ANALYTICS_ID\",\n],\n\"outputs\": [\".next/**\"],\n}\n},\n\"baseBranch\": \"origin/main\",\n\"globalDependencies\": [\n\"$GITHUB_TOKEN\"// env var that will impact the hashes of all tasks,\n\"tsconfig.json\" // file contents will impact the hashes of all tasks,\n\".env.*\" // glob file contents will impact the hashes of all tasks,\n],\n}\n}\n\nPro Tip: In most monorepos, you're don't often use environment variables in shared packages, but mostly only in applications. Thus, to get higher cache hit rates, you should likely only include environment variables in the app-specific tasks where they are used/inlined.",
      "force-overwrite-cache#Force overwrite cache": "Conversely, if you want to force turbo to re-execute a previously cached task, add the --force flag:\n# Run `build` npm script in all packages and apps,\n# ignoring cache hits.\nturbo run build --force",
      "logs#Logs": "Not only does turbo cache the output of your tasks, it also records the terminal output (i.e. combined stdout and stderr) to (<package>/.turbo/run-<command>.log). When turbo encounters a cached task, it will replay the output as if it happened again, but instantly, with the package name slightly dimmed.",
      "hashing#Hashing": "By now, you're probably wondering how turbo decides what constitutes a cache hit vs. miss for a given task. Good question!First turbo constructs a hash of the current global state of the monorepo:\nThe contents of any files that satisfy the glob patterns and any the values of environment variables listed in globalDependencies\nThe sorted list environment variable key-value pairs that includes THASH anywhere in their names (e.g. STRIPE_PUBLIC_THASH_SECRET_KEY but not STRIPE_PUBLIC_KEY)\n\nThen it adds on more factors relative to a given package's task:\nHash the contents of all not-gitignored files in the package folder\nThe hashes of all internal dependencies\nThe outputs option specified in the pipeline\nThe set of resolved versions of all installed dependencies, devDependencies, and optionalDependencies specified in a package's package.json from the root lockfile\nThe package task's name\nThe sorted list of environment variable key-value pairs that correspond to the environment variable names listed in applicable pipeline.<task-or-package-task>.dependsOn list.\n\nOnce turbo encounters a given package's task in its execution, it checks the cache (both locally and remotely) for a matching hash. If it's a match, it skips executing that task, moves or downloads the cached output into place and replays the previously recorded logs instantly. If there isn't anything in the cache (either locally or remotely) that matches the calculated hash, turbo will execute the task locally and then cache the specified outputs using the hash as an index.The hash of a given task is injected at execution time as an environment variable TURBO_HASH. This value can be useful in stamping outputs or tagging Dockerfile etc.\nAs of turbo v0.6.10, turbo's hashing algorithm when using npm or pnpm\ndiffers slightly from the above. When using either of these package managers,\nturbo will include the hashed contents of the lockfile in its hash\nalgorithm for each package's task. It will not parse/figure out the resolved\nset of all dependencies like the current yarn implementation."
    }
  },
  "/docs/features/pipelines": {
    "title": "Pipelines",
    "data": {
      "": "In traditional monorepo task runners, like lerna or even yarn's own built-in workspaces run command, each NPM lifecycle script like build or test is run topologically (which is the mathematical term for \"dependency-first\" order) or in parallel individually. Depending on the dependency graph of the monorepo, CPU cores might be left idleâ€”wasting valuable time and resources.Turborepo gives developers a way to specify task relationships explicitly and conventionally. The advantage here is twofold.\nIncoming new developers can look at the Turborepo pipeline and understand how tasks are related.\nturbo can use this explicit declaration to perform an optimized and scheduled execution based on the abundant availability of multi-core processors.\n\nTo give you a sense of how powerful this can be, the below diagram compares the turbo vs lerna task execution timelines:Notice that turbo is able to schedule tasks efficiently--collapsing waterfalls--whereas lerna can only execute one task a time. The results speak for themselves.",
      "defining-a-pipeline#Defining a pipeline": "To define your project's task dependency graph, use the pipeline key in the root package.json's turbo configuration. turbo interprets this configuration and conventions to properly schedule, execute, and cache the outputs of the tasks in your project.Each key in the pipeline object is the name of a task that can be executed by turbo run. You can specify its dependencies with the dependsOn key beneath it as well as some other options related to caching.An example Pipeline configuration:\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"build\"]\n},\n\"deploy\": {\n\"dependsOn\": [\"build\", \"test\", \"lint\"]\n},\n\"lint\": {}\n}\n}\n}\nThe rough execution order for a given package based on the dependsOn keys above will be:\nbuild once its dependencies have run their build commands\ntest once its own build command is finished\nlint whenever\ndeploy once its own build, test, and lint commands have finished\n\nThe full pipeline can then be run:\nnpx turbo run build test lint deploy\nTurborepo will then efficiently schedule execution minimizing idle CPUs.",
      "task-dependency-format#Task Dependency Format": "What you are declaring here in the pipeline object of the turbo configuration is a dependency graph of tasks. In the above example, in plain english, the configuration translates to the following conventions:\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// A package's `build` task depends on that package's\n// topological dependencies' and devDependencies'\n// `build` tasks  being completed\n// (that's what the `^` symbol signifies).\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// A package's `test` task depends on the `build`\n// task of the same package being completed.\n\"dependsOn\": [\"build\"]\n},\n\"deploy\": {\n// A package's `deploy` task depends on the `build`,\n// `test`, and `lint` tasks of the same package\n// being completed.\n\"dependsOn\": [\"build\", \"test\", \"lint\"]\n},\n// A package's `lint` task has no dependencies and\n// can be run whenever.\n\"lint\": {}\n}\n}\n}",
      "topological-dependency#Topological Dependency": "The ^ symbol explicitly declares that the task has a package-topological dependency on another task.A common pattern in many TypeScript monorepos is to declare that a package's build task (e.g. tsc) should only run once the build tasks of all of its dependencies in the monorepo have run their own build tasks. This type of relationship can be expressed as follows:\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// \"A package's `build` command depends on its dependencies'\n// and devDependencies' `build` commands being completed first\"\n\"dependsOn\": [\"^build\"]\n}\n// ... omitted for brevity\n}\n}\n}",
      "empty-dependency-list#Empty Dependency List": "An empty dependency list (dependsOn is either undefined or []) means that a task can start executing whenever it can! After all, it has NO dependencies.\n{\n\"turbo\": {\n\"pipeline\": {\n// ... omitted for brevity\n\n// A package's `lint` command has no dependencies and can be run at\n// whenever.\n\"lint\": {}\n}\n}\n}",
      "tasks-that-are-in-the-pipeline-but-not-in-some-packagejson#Tasks that are in the pipeline but not in SOME package.json": "Sometimes tasks declared in the pipeline are not present in all packages' package.json files. turbo will automatically and gracefully ignore those. No problem!",
      "pipeline-tasks-are-the-only-ones-that-turbo-knows-about#pipeline tasks are the only ones that turbo knows about": "turbo will only account for tasks declared in the pipeline configuration. If it's not listed there, turbo will not know how to run them.",
      "implicit-dependencies-and-specific-package-tasks#Implicit Dependencies and Specific Package Tasks": "Sometimes you need to manually place a package-task dependency on another package-task. This can occur especially in repos that are just coming off of a lerna or rush repository where the tasks are traditionally run in separate phases. Sometimes assumptions are made for those repositories that are not expressible in the simple task pipeline configuration, as seen above.\nAdditionally, you may need to express implicit dependencies or sequences between applications or microservices when using turbo in CI/CD.For these cases, you can express these relationships in your pipeline configuration like this:\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"dependsOn\": [\"build\"]\n},\n\"deploy\": {\n\"dependsOn\": [\"test\"]\n},\n\"frontend#deploy\": {\n\"dependsOn\": [\"ui#test\", \"backend#deploy\", \"backend#health-check\"]\n}\n}\n}\n}\nIn this example, we illustrate a deploy script of a frontend application depends on both the deploy and health-check NPM scripts of backend as well as the test script of a ui package. The syntax is <package>#<task>.This seems like it goes against the \"test\": { \"dependsOn\": [\"build\"] } and \"deploy\": { \"dependsOn\": [\"test\"] }, but it does not. Since test and deploy scripts do not have topological dependencies (e.g. ^<task>), they theoretically can get triggered anytime once their own package's build and test scripts have finished! Unless they are being used for applications/services for deployment orchestration, the general guidance is to get rid of these specific package-task to package-task dependencies in the pipeline as quickly as possible (so the builds can be optimized better).\nNote: Package-tasks do not inherit cache configuration. You must redeclare\noutputs at the moment.\n\nTurborepo's Pipeline API design and this page of documentation was inspired by Microsoft's Lage project.\nShoutout to Kenneth Chau for the idea of fanning out tasks in such a concise and elegant way."
    }
  },
  "/docs/features/scopes": {
    "title": "Scoped Tasks",
    "data": {
      "": "Scoping task execution can speed up the process especially if there are distinct clusters of packages that are not related to each other within your repository. Turborepo has a scope option that allows the task running to proceed up to the packages found that matches the scope argument. It's useful to think of scope as an \"entry point\" into your monorepo's package/task graph. This is a string matcher based on the name of the packages (not the package path).\nIt is important to note that dependents and dependencies refer to the\npackage and task.",
      "scoped-tasks-with-all-its-dependents#Scoped tasks with all its dependents": "By default, it is helpful to be able to run tasks on all affected packages within a scope. Packages that changed will affect downstream consumers. In this case, pass along the scope to build all the dependencies as well.\nYou can use wildcard character: *. This is particularly helpful when\npackages are named by group or by scope.\n\nturbo run build --scope=*build-tools*",
      "scoped-tasks-with-no-dependents--their-dependencies#Scoped tasks with no dependents & their dependencies": "Sometimes we want to run the tasks needed to satisfy the build script of all the packages that has the build-tools string in their names. Think of this as running tasks up and including the package matched in the scope. Add a --no-deps flag to run up to a package task.\nturbo run build --scope=*build-tools* --no-deps --include-dependencies\n\nTurborepo's Scoped Tasks API design and docs were/are inspired Microsoft's Lage project --scope flag which was inspired by Lerna's.We are working toward a new, more expressive task filtering/scoping syntax. Read the RFC here."
    }
  },
  "/docs/features/remote-caching": {
    "title": "Remote Caching (Beta)",
    "data": {
      "": "A major key ðŸ”‘ to Turborepo's speed is that it is both lazy and efficientâ€”it does the least amount of work possible and it tries to never redo work that's already been done before.At the moment, your Turborepo caches your tasks on your local filesystem (i.e. \"single-player mode,\" if you will). However, what if there was a way to take advantage of the computational work done by your teammates or your CI (i.e. \"co-op multiplayer mode\")?What if there was a way to teleport and share a single cache across machines? Almost like a \"Dropbox\" for your Turborepo cache.\nRemote Caching has entered the chat.\nTurborepo can use a technique known as Remote Caching to share cache artifacts across machines for an additional speed boost. This is possible because Turborepo uses content addressable storage.\nRemote Caching is a powerful feature of Turborepo, but with great power comes great responsibility. Make sure you are caching correctly first and double check handling of environment variables. Please also remember Turborepo treats logs as artifacts, so be aware of what you are printing to the console.",
      "vercel#Vercel": "",
      "for-local-development#For Local Development": "If you want to link your local turborepo to your Remote Cache you do so by first authenticating the Turborepo CLI with your Vercel account:\nnpx turbo login\nNext, you can link your turborepo to your remote cache by running the following command:\nnpx turbo link\nOnce enabled, make some changes to a package or application you are currently caching and run tasks against it with turbo run.\nYour cache artifacts will now be stored locally and in your Remote Cache.To verify, delete your local Turborepo cache with:\nrm -rf ./node_modules/.cache/turbo\nThen run the same build again. If things are working properly, turbo should not execute tasks locally, but rather download both the logs and artifacts from your Remote Cache and replay them back to you.",
      "remote-caching-on-vercel-builds#Remote Caching on Vercel Builds": "If you are building and hosting your apps on Vercel, then Remote Caching will be automatically set up for you on your behalf once you use turbo. You need to update your build settings to build with turbo.Please refer to the Vercel documentation for instructions.",
      "custom-remote-caches#Custom Remote Caches": "You can self-host your own Remote Cache or use other remote caching service providers as long as they comply with Turborepo's Remote Caching Server API.You can set / control the remote caching domain by specifying the --api and --token flags, where --api is the hostname and --token is a bearer token.\nturbo run build --api=\"https://my-server.example.com\" --token=\"xxxxxxxxxxxxxxxxx\"\nYou can see the endpoints / requests needed here."
    }
  },
  "/docs/guides/complimentary-tools": {
    "title": "Complimentary Tools",
    "data": {
      "": "Below is a running list of additional monorepo tools that you may find useful in your turborepo.ðŸ’¯ = stuff we use or have used in Turborepo's own monorepo",
      "versioning-publishing-and-changelog-generation#Versioning, Publishing, and Changelog Generation": "For the foreseeable future, turbo is not going to deal with package publishing. Versioning/Publishing is an extremely opinionated topic with a lot of existing solutions. Our advice is to avoid versioning packages altogether unless you actually need to publish them to NPM for external consumption. If you have to version your packages, we really like the workflow of Changesets (especially for open source projects).\nchangesets/changesets - ðŸ¦‹ A way to manage your versioning and changelogs with a focus on monorepos\nmicrosoft/beachball - The Sunniest Semantic Version Bumper\nlerna/lerna - A tool for managing JavaScript projects with multiple packages.\nlerna/lerna-changelog - PR-based changelog generator with monorepo support\nintuit/auto - Generate releases based on semantic version labels on pull requests.",
      "codebase-linting#Codebase Linting": "typicode/husky - Modern native Git hooks made easy!\nokonet/lint-staged - Run linters on git staged files\ndanger/danger-js - âš ï¸ Stop saying \"you forgot to â€¦\" in code review",
      "e2e-testing#e2e Testing": "cypress-io/cypress - Fast, easy and reliable testing for anything that runs in a browser. ðŸ’¯\ncypress-io/github-action - Run Cypress in GitHub Actions\nmicrosoft/playwright - Build a cross-browser end-to-end test suite with Playwright.\nmicrosoft/playwright-github-action - Run Playwright tests on GitHub Actions",
      "automation#Automation": "Kodiak - Automate your GitHub Pull Request merge behavior ðŸ’¯\npreactjs/compressed-size-action - GitHub Action that adds compressed size changes to your PRs.\nDependabot - Automated dependency updates built into GitHub ðŸ’¯",
      "codemods-and-code-generation#Codemods and Code Generation": "We are planning to officially add code generation to turbo sometime in the future. In the meantime, we suggest using plopjs/plop.\nsapegin/mrm - Codemods for your project config files ðŸ’¯\nplopjs/plop - Codegen CLI ðŸ’¯\nfacebook/jscodeshift - A JavaScript codemod toolkit. ðŸ’¯\ncodemod-js/codemod - Rewrites JavaScript and TypeScript using babel plugins.\nairbnb/ts-migrate - A tool to help migrate JavaScript code quickly and conveniently to TypeScript\ndotansimha/graphql-code-generator - A tool for generating code based on a GraphQL schema and GraphQL operations (query/mutation/subscription), with flexible support for custom plugins. ðŸ’¯\nswagger-api/swagger-codegen - swagger-codegen contains a template-driven engine to generate documentation, API clients and server stubs in different languages by parsing your OpenAPI / Swagger definition.",
      "infrastructure-as-code#Infrastructure as Code": "One of the cool things we discovered when building Turborepo is how beautifully it works with infrastructure-as-code solutions. We currently use Pulumi, but the AWS CDK is also pretty cool.\npulumi/pulumi - Modern Infrastructure as Code. Any cloud, any language ðŸ’¯\naws/aws-cdk - The AWS Cloud Development Kit is a framework for defining cloud infrastructure in code",
      "miscellaneous#Miscellaneous": "volta-cli/volta - JS Toolchains as Code (A better NVM) ðŸ’¯ ðŸ’¯ ðŸ’¯ ðŸ’¯ ðŸ’¯\nds300/patch-package - Fix broken node modules instantly (without forking) ðŸ’¯ ðŸ’¯ ðŸ’¯\natlassian/yarn-deduplicate - Deduplication tool for yarn.lock files ðŸ’¯ ðŸ’¯ ðŸ’¯ ðŸ’¯ ðŸ’¯\nwclr/yalc - Work with yarn/npm packages locally like a boss. (It's like yarn link that actually works)\nverdaccio/verdaccio - ðŸ“¦ðŸ”A lightweight private proxy registry build in Node.js"
    }
  },
  "/docs/guides/migrate-from-lerna": {
    "title": "Migrate from Lerna",
    "data": {
      "": "Turborepo and Lerna have a lot a in common, but also some key differences.tl;dr you can use Lerna and Turbo together.\nUse lerna symlinking (lerna bootstrap) packages, publishing and changelog generation\nUse turbo for task running and caching",
      "tool-comparison#Tool Comparison": "Lerna is a monorepo task runner and NPM workspace implementation. Both Turborepo and Lerna can be used to run tasks across packages in parallel and also topologically (i.e. if A depends on B, run B before A).",
      "caching#Caching": "However, unlike Turborepo, Lerna has no ability to cache prior work or intelligently schedule tasks (i.e. create pipelines).",
      "task-scheduling#Task Scheduling": "Turborepo's task scheduler is more powerful than Lerna's (which can only schedule one task at a time) thanks to Turborepo pipelines. Turborepo reduces idle CPUs, saves compute resource, and collapse waterfallsâ€”which ultimately results in faster overall builds.Let's look at an example. Imagine you have two packages A and B each with 3 tasks build, test, and bundle, where A depends on B being built....The above may not not look like much. But imagine that A's build task takes 20 minutes and now look at when B's tests run. Woah....yeah....scheduling can save insane amounts of time when you have long build times.",
      "package-publishing-versioning-and-changelog-generation#Package Publishing, Versioning, and Changelog Generation": "Lerna can version and publish packages to NPM registries as well as create changelogs. It's extremely good at this, especially for releasing canary pre-releases. While Turborepo may eventually tackle these features, at the time of writing, it is not a high priority goal (we suggest using Changesets in the meantime). If Changesets isn't for you, and you want to stick with Lerna's publish flow, you can use Lerna and Turborepo together.",
      "example-migration#Example migration": "Say you have a Lerna-powered monorepo setup like so:\n// lerna.json\n{\n\"npmClient\": \"yarn\",\n\"packages\": [\"packages/*\"],\n\"command\": {\n\"version\": {\n\"exact\": true\n},\n\"publish\": {\n\"npmClient\": \"npm\",\n\"allowBranch\": [\"master\", \"canary\"],\n\"registry\": \"https://registry.npmjs.org/\"\n}\n},\n\"version\": \"2.1.6\"\n}\n\n{\n\"private\": true,\n\"scripts\": {\n\"dev\": \"lerna run dev --stream --parallel\",\n\"test\": \"lerna run test\",\n\"build\": \"lerna run build\",\n\"prepublish\": \"lerna run prepublish\",\n\"publish-canary\": \"lerna version prerelease --preid canary --force-publish\",\n\"publish-stable\": \"lerna version --force-publish && release && node ./scripts/release-notes.js\"\n},\n\"devDependencies\": {\n\"lerna\": \"^3.19.0\"\n}\n}\nTo add turbo, run the following command in your terminal\nyarn add turbo --dev -W\nAlter package.json to use turbo for task running, but keep lerna for versioning.\n{\n\"private\": true,\n\"scripts\": {\n-   \"dev\": \"lerna run dev --stream --parallel\",\n+   \"dev\": \"turbo run dev --parallel --no-cache\",\n-   \"test\": \"lerna run test\",\n+   \"test\": \"turbo run test\",\n-   \"build\": \"lerna run build\",\n+   \"build\": \"turbo run build\",\n\"prepublish\": \"lerna run prepublish\",\n\"publish-canary\": \"lerna version prerelease --preid canary --force-publish\",\n\"publish-stable\": \"lerna version --force-publish && release && node ./scripts/release-notes.js\"\n},\n\"devDependencies\": {\n\"lerna\": \"^3.19.0\",\n+   \"turbo\": \"*\"\n},\n+ \"turbo\": {\n+   \"pipeline\": {\n+     \"build\": {\n+       \"dependsOn\": [\"^build\"],\n+       \"outputs\": [\"dist/**\"]\n+     },\n+     \"test\": {\n+       \"outputs\": []\n+     },\n+     \"dev\": {\n+       \"cache\": false\n+     }\n+   }\n}\n}\nIf you're not using yarn or NPM workspaces with Lerna, you should keep around your lerna bootstrap command if you have one. Turborepo considers Lerna a valid workspace implementation. Everything should work as expected."
    }
  },
  "/docs/reference/codemods": {
    "title": "Codemods",
    "data": {
      "": "Turborepo provides Codemod transformations and automatic migration scripts to help upgrade your Turborepo codebase when a feature is deprecated.Codemods are transformations that run on your codebase programmatically. This allows for a large amount of changes to be applied without having to manually go through every file.",
      "usage#Usage": "npx @turbo/codemod <transform> <path>\n\ntransform - name of transform, see available transforms below.\npath - files or directory to transform\n--dry - Do a dry-run, no code will be edited\n--print - Prints the changed output for comparison",
      "turborepo-1x#Turborepo 1.x": "",
      "add-package-manager#add-package-manager": "Transforms the root package.json so that packageManager key as the detected package manager (yarn, npm, pnpm) and version (e.g. yarn@1.22.17). This key is now supported by Node.js and is used by Turborepo for faster package manager detection (vs. inferring from just the filesystem alone).For example, for Yarn v1:\n// Before\n{\n\"name\": \"turborepo-basic\",\n\"version\": \"0.0.0\",\n\"private\": true,\n\"workspaces\": [\n\"apps/*\",\n\"packages/*\"\n],\n...\n}\n\n// After\n{\n\"name\": \"turborepo-basic\",\n\"version\": \"0.0.0\",\n\"private\": true,\n\"packageManager\": \"yarn@1.22.17\",\n\"workspaces\": [\n\"apps/*\",\n\"packages/*\"\n],\n...\n}",
      "usage-1#Usage": "Go to your project:\ncd path-to-your-turborepo/\nRun the codemod:\nnpx @turbo/codemod add-package-manager"
    }
  },
  "/docs/reference/command-line-reference": {
    "title": "CLI Usage",
    "data": {
      "": "After installing the turbo package (or cloning a starter), you can start using Turborepo's command line interface (CLI) turbo to do all kinds of awesomeness in your monorepo.",
      "option-syntax#Option Syntax": "Options can be passed to turbo in different ways. Options that require a value can be passed with an equals sign:\n--<option>=<value>\n--<option>=\"<value with a space>\"\nBoolean options can be enabled as follows:\n--no<option>\n--<option>=false",
      "turbo-run-task1-task2#turbo run <task1> <task2>": "Run NPM scripts across all packages in specified scope. Tasks must be specified in your pipeline configuration.",
      "options#Options": "",
      "--cache-dir#--cache-dir": "type: stringDefaults to ./node_modules/.cache/turbo. Specify local filesystem cache directory. Be sure to add this folder to your .gitignore if you change it from the default.\nturbo run build --cache-dir=\"./my-cache\"",
      "--concurrency#--concurrency": "type: numberDefaults to 10. Set/limit the max concurrency of task execution. This must be an integer greater than or equal to 1. Use 1 to force serial (i.e. one task at a time) execution. This option is ignored if the --parallel flag is also passed.\nturbo run build --concurrency=10\nturbo run test --concurrency=1",
      "--continue#--continue": "Defaults to false. This flag tells turbo whether or not to continue with execution in the presence of an error (i.e. non-zero exit code from a task).\nBy default, specifying the --parallel flag will automatically set --continue to true unless explicitly set to false.\nWhen --continue is true, turbo will exit with the highest exit code value encountered during execution.\nturbo run build --continue",
      "--cwd#--cwd": "Set the working directory of the command.\nturbo run build --cwd=./somewhere/else",
      "--deps#--deps": "Defaults to true. Include dependent packages/apps consumers in the execution.\nturbo run build --deps\nturbo run build --no-deps\nExampleLet's say you have packages A, B, C, and D where A depends on B and C depends on D. You run turbo run build for the first time and everything is built and cached. Then, you change a line of code in B. With the --deps flag on, running turbo run build will execute build in B and then A, but not in C and D because they are not impacted by the change. If you were to run turbo run build --no-deps instead, turbo will only run build in B.",
      "--graph#--graph": "type: stringIf Graphviz is installed, this command will generate an svg, png, jpg, pdf, json, html, or other supported output formats of the current task graph.\nThe output file format can be controlled with the filename's extension if it is specified. If a filename is not specified, graph-<timestamp>.jpg is outputted.If Graphviz is not installed, this command prints the dot graph to stdout.\nturbo run build --graph\nturbo run build test lint --graph=my-graph.svg\nturbo run build test lint --graph=my-json-graph.json\nturbo run build test lint --graph=my-graph.pdf\nturbo run build test lint --graph=my-graph.png\nturbo run build test lint --graph=my-graph.html\n\nKnown Bug: All possible pipeline task nodes will be added to the\ngraph at the moment, even if that pipeline task does not actually exist in a\ngiven package. This has no impact on execution, it means that:\nthe terminal output may overstate the number of packages in which a task is running.\nyour dot viz graph may contain additional nodes that represents tasks that do not exist.",
      "--force#--force": "Ignore existing cached artifacts and forcibly re-execute all tasks (overwriting artifacts that overlap)\nturbo run build --force",
      "--global-deps#--global-deps": "Specify glob of global filesystem dependencies to be hashed. Useful for .env and files in the root directory that impact multiple packages/apps.\nCan be specified multiple times.\nturbo run build --global-deps=\".env.*\" --global-deps=\".eslintrc\" --global-deps=\"jest.config.js\"\nYou can also specify these in your turbo configuration as globalDependencies key.",
      "--ignore#--ignore": "type: string[]Ignore files or directories from impacting scope. Uses glob patterns via multimatch under the hood.\nturbo run build --ignore=\"apps/**/*\"\nturbo run build --ignore=\"packages/**/*\"\nturbo run build --ignore=\"packages/**/*\" --ignore=\"\\!/packages/not-this-one/**/*\"",
      "how-multiple-patterns-work#How multiple patterns work": "Positive patterns (e.g. foo or *) add to the results, while negative patterns (e.g. !foo) subtract from the results.Therefore a lone negation (e.g. ['!foo']) will never match anything â€“ use ['*', '!foo'] instead.",
      "globbing-patterns#Globbing patterns": "Just a quick overview.\n* matches any number of characters, but not /\n? matches a single character, but not /\n** matches any number of characters, including /, as long as it's the only thing in a path part\n{} allows for a comma-separated list of \"or\" expressions\n! at the beginning of a pattern will negate the match",
      "--include-dependencies#--include-dependencies": "Default false. When true, turbo will add any packages that the packages in the current execution scope depend on (i.e. those declared in dependencies or devDependencies).This is useful when using --scope in CI as it guarantees that every dependency needed for the execution scope is actually executed.",
      "--no-cache#--no-cache": "Default false. Do not cache results of the task. This is useful for watch commands like next dev or react-scripts start.\nturbo run build --no-cache\nturbo run dev --parallel --no-cache",
      "--only#--only": "Default false. Restricts execution to only include specified tasks. This is very similar to how how lerna or pnpm run tasks by default.Given this pipeline:\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\n\"^build\"\n]\n},\n\"test\": {\n\"dependsOn\": [\n\"^build\"\n]\n}\n}\n}\n}\n\nturbo run test --only\nWill execute only the test tasks in each package. It will not build.",
      "--parallel#--parallel": "Default false. Run commands in parallel across packages and apps and ignore the dependency graph. This is useful for developing with live reloading.\nturbo run lint --parallel --no-cache\nturbo run dev --parallel --no-cache",
      "--scope#--scope": "type: string[]Specify/filter package(s)/apps to act as entry points for execution. Globs against package.json name field (and not the file system.)\nturbo run lint --scope=\"@example/**\"\nturbo run dev --parallel --scope=\"@example/a\" --scope=\"@example/b\" --no-cache --no-deps",
      "--serial#--serial": "Deprecated in v0.5.3: Use --concurrency=1 instead.Executes all tasks serially (i.e. one-at-a-time).\nturbo run build --serial",
      "--since#--since": "Filter execution based on which packages have changed since a merge-base.\nturbo run build --since=origin/main\n\nImportant: This uses the git diff ${target_branch}... mechanism to\nidentify which packages have changed. There is an assumption that all the\ninput files for a package exist inside their respective package/app folders.",
      "--token#--token": "A bearer token for remote caching. Useful for running in non-interactive shells (e.g. CI/CD) in combination with --team flags.\nturbo run build --team=my-team --token=xxxxxxxxxxxxxxxxx\nYou can also set the value of the current token by setting an environment variable named TURBO_TOKEN. The flag will take precedence over the environment variable if both are present.If you're using Remote Caching on Vercel, and your building your project on Vercel, this environment variable and flag are not needed because they are automatically set for you. If youâ€™re using Remote Caching on Vercel, but building in another CI provider like CircleCI or GitHub Actions, you can use a Vercel Personal Access Token as your â€”token or TURBO_TOKEN. If you are using a custom Remote Cache, this value will be used to send an HTTP Bearer token with requests to your custom Remote Cache.",
      "--team#--team": "The slug of the remote cache team. Useful for running in non-interactive shells in combination with --token and --team flags.\nturbo run build --team=my-team\nturbo run build --team=my-team --token=xxxxxxxxxxxxxxxxx\nYou can also set the value of the current team by setting an environment variable named TURBO_TEAM. The flag will take precedence over the environment variable if both are present.",
      "--trace#--trace": "type: stringTo view CPU trace, outputs the trace to the given file, use go tool trace [file].\nImportant: The trace viewer doesn't work under Windows Subsystem for Linux.\n\nturbo run build --trace=\"<trace-file-name>\"",
      "--heap#--heap": "type: stringTo view heap trace, outputs the trace to the given file, use go tool pprof [file] and type top. You can also drop it into speedscope and use the left heavy or sandwich view modes.\nturbo run build --heap=\"<heap-file-name>\"",
      "--cpuprofile#--cpuprofile": "type: stringTo view CPU profile, outputs the profile to the given file, drop the file into speedscope.\nImportant: The CPU profiler doesn't work under\nWindows subsystem for Linux. The profiler has to be built\nfor native Windows and run using the command prompt instead.\n\nturbo run build --cpuprofile=\"<cpu-profile-file-name>\"",
      "-v--vv--vvv#-v, -vv, -vvv": "To specify log level, use -v for Info, -vv for Debug and -vvv for Trace flags.\nturbo run build -v\nturbo run build -vv\nturbo run build -vvv",
      "turbo-prune---scopetarget#turbo prune --scope=<target>": "Generate a sparse/partial monorepo with a pruned lockfile for a target package.This command will generate folder called out with the following inside of it:\nThe full source code of all internal packages that are needed to build the target\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the packages in the pruned workspace.\nA copy of the root package.json\n\n\n.                                 # Folder full source code for all package needed to build the target\nâ”œâ”€â”€ package.json                  # The root `package.json`\nâ”œâ”€â”€ packages\nâ”‚   â”œâ”€â”€ ui\nâ”‚   â”‚   â”œâ”€â”€ package.json\nâ”‚   â”‚   â”œâ”€â”€ src\nâ”‚   â”‚   â”‚   â””â”€â”€ index.tsx\nâ”‚   â”‚   â””â”€â”€ tsconfig.json\nâ”‚   â”œâ”€â”€ shared\nâ”‚   â”‚   â”œâ”€â”€ package.json\nâ”‚   â”‚   â”œâ”€â”€ src\nâ”‚   â”‚   â”‚   â”œâ”€â”€ __tests__\nâ”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ sum.test.ts\nâ”‚   â”‚   â”‚   â”‚   â””â”€â”€ tsconfig.json\nâ”‚   â”‚   â”‚   â”œâ”€â”€ index.ts\nâ”‚   â”‚   â”‚   â””â”€â”€ sum.ts\nâ”‚   â”‚   â””â”€â”€ tsconfig.json\nâ”‚   â””â”€â”€ frontend\nâ”‚       â”œâ”€â”€ next-env.d.ts\nâ”‚       â”œâ”€â”€ next.config.js\nâ”‚       â”œâ”€â”€ package.json\nâ”‚       â”œâ”€â”€ src\nâ”‚       â”‚   â””â”€â”€ pages\nâ”‚       â”‚       â””â”€â”€ index.tsx\nâ”‚       â””â”€â”€ tsconfig.json\nâ””â”€â”€ yarn.lock                            # The pruned lockfile for all targets in the subworkspace",
      "options-1#Options": "",
      "--docker#--docker": "type: booleanDefault to false. Passing this flag will alter the outputted folder with the pruned workspace to make it easier to use with Docker best practices / layer caching.With the --docker flag. The prune command will generate folder called out with the following inside of it:\nA folder json with the pruned workspace's package.jsons\nA folder full with the pruned workspace's full source code, but only including the internal packages that are needed to build the target.\nA new pruned lockfile that only contains the pruned subset of the original root lockfile with the dependencies that are actually used by the packages in the pruned workspace.\n\n\n.\nâ”œâ”€â”€ full                                # Folder full source code for all package needed to build the target\nâ”‚   â”œâ”€â”€ package.json\nâ”‚   â””â”€â”€ packages\nâ”‚       â”œâ”€â”€ ui\nâ”‚       â”‚   â”œâ”€â”€ package.json\nâ”‚       â”‚   â”œâ”€â”€ src\nâ”‚       â”‚   â”‚   â””â”€â”€ index.tsx\nâ”‚       â”‚   â””â”€â”€ tsconfig.json\nâ”‚       â”œâ”€â”€ shared\nâ”‚       â”‚   â”œâ”€â”€ package.json\nâ”‚       â”‚   â”œâ”€â”€ src\nâ”‚       â”‚   â”‚   â”œâ”€â”€ __tests__\nâ”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ sum.test.ts\nâ”‚       â”‚   â”‚   â”‚   â””â”€â”€ tsconfig.json\nâ”‚       â”‚   â”‚   â”œâ”€â”€ index.ts\nâ”‚       â”‚   â”‚   â””â”€â”€ sum.ts\nâ”‚       â”‚   â””â”€â”€ tsconfig.json\nâ”‚       â””â”€â”€ frontend\nâ”‚           â”œâ”€â”€ next-env.d.ts\nâ”‚           â”œâ”€â”€ next.config.js\nâ”‚           â”œâ”€â”€ package.json\nâ”‚           â”œâ”€â”€ src\nâ”‚           â”‚   â””â”€â”€ pages\nâ”‚           â”‚       â””â”€â”€ index.tsx\nâ”‚           â””â”€â”€ tsconfig.json\nâ”œâ”€â”€ json                                # Folder containing just package.jsons for all targets in the subworkspace\nâ”‚   â”œâ”€â”€ package.json\nâ”‚   â””â”€â”€ packages\nâ”‚       â”œâ”€â”€ ui\nâ”‚       â”‚   â””â”€â”€ package.json\nâ”‚       â”œâ”€â”€ shared\nâ”‚       â”‚   â””â”€â”€ package.json\nâ”‚       â””â”€â”€ frontend\nâ”‚           â””â”€â”€ package.json\nâ””â”€â”€ yarn.lock                           # The pruned lockfile for all targets in the subworkspace",
      "turbo-login#turbo login": "Connect machine to your Remote Cache provider. The default provider is Vercel.",
      "options-2#Options": "",
      "--url#--url": "type: stringDefaults to https://vercel.com.",
      "--api#--api": "type: stringDefaults to https://api.vercel.com.",
      "turbo-link#turbo link": "Link the current directory to Remote Cache scope. The selected owner (either a user or and organization) will be able to share cache artifacts through Remote Caching.\nYou should run this command from the root of your monorepo.",
      "options-3#Options": "",
      "--api-1#--api": "type: stringDefaults to https://api.vercel.com",
      "turbo-unlink#turbo unlink": "Unlink the current directory from the Remote Cache"
    }
  },
  "/docs/reference/configuration": {
    "title": "Configuration Options",
    "data": {
      "": "You can configure the behavior of turbo by adding a turbo object in the package.json in your monorepo's root (i.e. the same one you specify your workspaces key is set for Yarn and NPM users).",
      "basebranch#baseBranch": "type: stringDefaults to origin/master. The base branch or your git repository. Git is used by turbo in its hashing algorithm and --since CLI flag.",
      "globaldependencies#globalDependencies": "type: string[]A list of globs and environment variables for implicit global hash dependencies. Environment variables should be prefixed with $ (e.g. $GITHUB_TOKEN). Any other entry without this prefix, will be considered filesystem glob. The contents of these files will be included in the global hashing algorithm and affect the hashes of all tasks.\nThis is useful for busting the cache based on .env files (not in Git), environment variables, or any root level file that impacts package tasks (but are not represented in the traditional dependency graph (e.g. a root tsconfig.json, jest.config.js, .eslintrc, etc.)).Example\n{\n\"turbo\": {\n\"pipeline\": {\n// ... omitted for brevity\n},\n\n\"globalDependencies\": [\n\".env\", // contents will impact hashes of all tasks\n\"tsconfig.json\", // contents will impact hashes of all tasks\n\"$GITHUB_TOKEN\"// value will impact the hashes of all tasks\n]\n}\n}",
      "npmclient#npmClient": "type: \"yarn\" | \"npm\" | \"pnpm\"Defaults to yarn. The NPM client in-use in your project.",
      "pipeline#pipeline": "An object representing the task dependency graph of your project. turbo interprets these conventions to properly schedule, execute, and cache the outputs of tasks in your project.Each key in the pipeline object is the name of a task that can be executed by turbo run. If turbo finds a workspace package with a package.json scripts object with a matching key, it will apply the pipeline task configuration to that NPM script during execution. This allows you to use pipeline to set conventions across your entire Turborepo.\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"build\"]\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}\n}",
      "dependson#dependsOn": "type: string[]The list of tasks and environment variables that this task depends on.Prefixing an item in dependsOn with a ^ tells turbo that this pipeline task depends on the package's topological dependencies completing the task with the ^ prefix first (e.g. \"a package's build tasks should only run once all of its dependencies and devDependencies have completed their own build commands\").Items in dependsOn without ^ prefix, express the relationships between tasks at the package level (e.g. \"a package's test and lint commands depend on build being completed first\").Prefixing an item in dependsOn with a $ tells turbo that this pipeline task depends the value of that environment variable.Example: Basics\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n// \"A package's `build` command depends on its dependencies'\n// or devDependencies' `build` command being completed first\"\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// \"A package's `test` command depends on its own `lint` and\n// `build` commands first being completed\"\n\"dependsOn\": [\"lint\", \"build\"]\n},\n\"deploy\": {\n// \"A package's `deploy` command, depends on its own `build`\n// and `test` commands first being completed\"\n\"dependsOn\": [\"build\", \"test\"]\n},\n// A package's `lint` command has no dependencies\n\"lint\": {}\n}\n}\n}\nExample: Environment Variables and Tasks\n{\n\"turbo\": {\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": {\n\"^build\",\n\"$SOMETHING_ELSE\" // value will impact the hashes of all build tasks\n},\n\"outputs\": [\"dist/**\", \".next/**\"]\n},\n\"web#build\": {\n\"dependsOn\": [\n\"^build\",\n\"$STRIPE_SECRET_KEY\", // value will impact hash of only web's build task\n\"$NEXT_PUBLIC_STRIPE_PUBLIC_KEY\"\n],\n\"outputs\": [\".next/**\"]\n}\n},\n\"globalDependencies\": [\n\"$GITHUB_TOKEN\"// value will impact the hashes of all tasks\n]\n}\n}",
      "outputs#outputs": "type: string[]Defaults to [\"dist/**\", \"build/**\"]. The set of glob patterns of a task's cacheable filesystem outputs.Note: turbo automatically logs stderr/stdout to .turbo/run-<task>.log. This file is always treated as a cacheable artifact and never needs to be specified.Passing an empty array can be used to tell turbo that a task is a side-effect and thus doesn't emit any filesystem artifacts (e.g. like a linter), but you still want to cache its logs (and treat them like an artifact).Example\n{\n\"pipeline\": {\n\"build\": {\n// \"Cache all files emitted to package's dist/** or .next\n// directories by a `build` task\"\n\"outputs\": [\"dist/**\", \".next/**\"],\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n// \"Don't cache any artifacts of `test` tasks (aside from\n// logs)\"\n\"outputs\": [],\n\"dependsOn\": [\"build\"]\n},\n\"test:ci\": {\n// \"Cache the coverage report of a `test:ci` command\"\n\"outputs\": [\"coverage/**\"],\n\"dependsOn\": [\"build\"]\n},\n\"dev\": {\n// Never cache anything (including logs) emitted by a\n// `dev` task\n\"cache\": false\n}\n}\n}",
      "cache#cache": "type: booleanDefaults to true. Whether or not to cache the task outputs. Setting cache to false is useful for daemon or long-running \"watch\" or development mode tasks that you don't want to cache.Example\n{\n\"pipeline\": {\n\"build\": {\n\"dependsOn\": [\"^build\"]\n},\n\"test\": {\n\"outputs\": [],\n\"dependsOn\": [\"build\"]\n},\n\"dev\": {\n\"cache\": false\n}\n}\n}"
    }
  }
}
