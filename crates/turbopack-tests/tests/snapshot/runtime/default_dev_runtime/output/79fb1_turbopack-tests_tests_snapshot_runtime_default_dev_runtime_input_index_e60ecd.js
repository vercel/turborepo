{
  "version": 3,
  "sections": [
    {"offset": {"line": 11, "column": 0}, "map": {"version":3,"sources":["/turbopack/[turbopack]/shared/runtime-utils.ts"],"sourcesContent":["/**\n * This file contains runtime types and functions that are shared between all\n * TurboPack ECMAScript runtimes.\n *\n * It will be prepended to the runtime code of each runtime.\n */\n\n/* eslint-disable @next/next/no-assign-module-variable */\n\n/// <reference path=\"./runtime-types.d.ts\" />\n\ninterface Exports {\n  __esModule?: boolean;\n\n  [key: string]: any;\n}\n\ntype EsmNamespaceObject = Record<string, any>;\n\nconst REEXPORTED_OBJECTS = Symbol(\"reexported objects\");\n\ninterface BaseModule {\n  exports: Exports | Promise<Exports> | AsyncModulePromise;\n  error: Error | undefined;\n  loaded: boolean;\n  id: ModuleId;\n  children: ModuleId[];\n  parents: ModuleId[];\n  namespaceObject?:\n    | EsmNamespaceObject\n    | Promise<EsmNamespaceObject>\n    | AsyncModulePromise<EsmNamespaceObject>;\n  [REEXPORTED_OBJECTS]?: any[];\n}\n\ninterface Module extends BaseModule {}\n\ntype RequireContextMap = Record<ModuleId, RequireContextEntry>;\n\ninterface RequireContextEntry {\n  id: () => ModuleId;\n}\n\ninterface RequireContext {\n  (moduleId: ModuleId): Exports | EsmNamespaceObject;\n\n  keys(): ModuleId[];\n\n  resolve(moduleId: ModuleId): ModuleId;\n}\n\ntype GetOrInstantiateModuleFromParent = (\n  moduleId: ModuleId,\n  parentModule: Module\n) => Module;\n\ntype CommonJsRequireContext = (\n  entry: RequireContextEntry,\n  parentModule: Module\n) => Exports;\n\nconst hasOwnProperty = Object.prototype.hasOwnProperty;\nconst toStringTag = typeof Symbol !== \"undefined\" && Symbol.toStringTag;\n\nfunction defineProp(\n  obj: any,\n  name: PropertyKey,\n  options: PropertyDescriptor & ThisType<any>\n) {\n  if (!hasOwnProperty.call(obj, name))\n    Object.defineProperty(obj, name, options);\n}\n\n/**\n * Adds the getters to the exports object.\n */\nfunction esm(exports: Exports, getters: Record<string, () => any>) {\n  defineProp(exports, \"__esModule\", { value: true });\n  if (toStringTag) defineProp(exports, toStringTag, { value: \"Module\" });\n  for (const key in getters) {\n    defineProp(exports, key, { get: getters[key], enumerable: true });\n  }\n}\n\n/**\n * Makes the module an ESM with exports\n */\nfunction esmExport(\n  module: Module,\n  exports: Exports,\n  getters: Record<string, () => any>\n) {\n  module.namespaceObject = module.exports;\n  esm(exports, getters);\n}\n\nfunction ensureDynamicExports(module: Module, exports: Exports) {\n  let reexportedObjects = module[REEXPORTED_OBJECTS];\n\n  if (!reexportedObjects) {\n    reexportedObjects = module[REEXPORTED_OBJECTS] = [];\n    module.exports = module.namespaceObject = new Proxy(exports, {\n      get(target, prop) {\n        if (\n          hasOwnProperty.call(target, prop) ||\n          prop === \"default\" ||\n          prop === \"__esModule\"\n        ) {\n          return Reflect.get(target, prop);\n        }\n        for (const obj of reexportedObjects!) {\n          const value = Reflect.get(obj, prop);\n          if (value !== undefined) return value;\n        }\n        return undefined;\n      },\n      ownKeys(target) {\n        const keys = Reflect.ownKeys(target);\n        for (const obj of reexportedObjects!) {\n          for (const key of Reflect.ownKeys(obj)) {\n            if (key !== \"default\" && !keys.includes(key)) keys.push(key);\n          }\n        }\n        return keys;\n      },\n    });\n  }\n}\n\n/**\n * Dynamically exports properties from an object\n */\nfunction dynamicExport(\n  module: Module,\n  exports: Exports,\n  object: Record<string, any>\n) {\n  ensureDynamicExports(module, exports);\n\n  module[REEXPORTED_OBJECTS]!.push(object);\n}\n\nfunction exportValue(module: Module, value: any) {\n  module.exports = value;\n}\n\nfunction exportNamespace(module: Module, namespace: any) {\n  module.exports = module.namespaceObject = namespace;\n}\n\nfunction createGetter(obj: Record<string | symbol, any>, key: string | symbol) {\n  return () => obj[key];\n}\n\n/**\n * @returns prototype of the object\n */\nconst getProto: (obj: any) => any = Object.getPrototypeOf\n  ? (obj) => Object.getPrototypeOf(obj)\n  : (obj) => obj.__proto__;\n\n/** Prototypes that are not expanded for exports */\nconst LEAF_PROTOTYPES = [null, getProto({}), getProto([]), getProto(getProto)];\n\n/**\n * @param raw\n * @param ns\n * @param allowExportDefault\n *   * `false`: will have the raw module as default export\n *   * `true`: will have the default property as default export\n */\nfunction interopEsm(\n  raw: Exports,\n  ns: EsmNamespaceObject,\n  allowExportDefault?: boolean\n) {\n  const getters: { [s: string]: () => any } = Object.create(null);\n  for (\n    let current = raw;\n    (typeof current === \"object\" || typeof current === \"function\") &&\n    !LEAF_PROTOTYPES.includes(current);\n    current = getProto(current)\n  ) {\n    for (const key of Object.getOwnPropertyNames(current)) {\n      getters[key] = createGetter(raw, key);\n    }\n  }\n\n  // this is not really correct\n  // we should set the `default` getter if the imported module is a `.cjs file`\n  if (!(allowExportDefault && \"default\" in getters)) {\n    getters[\"default\"] = () => raw;\n  }\n\n  esm(ns, getters);\n  return ns;\n}\n\nfunction esmImport(\n  sourceModule: Module,\n  id: ModuleId\n): Exclude<Module[\"namespaceObject\"], undefined> {\n  const module = getOrInstantiateModuleFromParent(id, sourceModule);\n  if (module.error) throw module.error;\n\n  // any ES module has to have `module.namespaceObject` defined.\n  if (module.namespaceObject) return module.namespaceObject;\n\n  // only ESM can be an async module, so we don't need to worry about exports being a promise here.\n  const raw = module.exports;\n  return (module.namespaceObject = interopEsm(\n    raw,\n    {},\n    (raw as any).__esModule\n  ));\n}\n\nfunction commonJsRequire(sourceModule: Module, id: ModuleId): Exports {\n  const module = getOrInstantiateModuleFromParent(id, sourceModule);\n  if (module.error) throw module.error;\n  return module.exports;\n}\n\ntype RequireContextFactory = (map: RequireContextMap) => RequireContext;\n\nfunction requireContext(\n  sourceModule: Module,\n  map: RequireContextMap\n): RequireContext {\n  function requireContext(id: ModuleId): Exports {\n    const entry = map[id];\n\n    if (!entry) {\n      throw new Error(\n        `module ${id} is required from a require.context, but is not in the context`\n      );\n    }\n\n    return commonJsRequireContext(entry, sourceModule);\n  }\n\n  requireContext.keys = (): ModuleId[] => {\n    return Object.keys(map);\n  };\n\n  requireContext.resolve = (id: ModuleId): ModuleId => {\n    const entry = map[id];\n\n    if (!entry) {\n      throw new Error(\n        `module ${id} is resolved from a require.context, but is not in the context`\n      );\n    }\n\n    return entry.id();\n  };\n\n  return requireContext;\n}\n\n/**\n * Returns the path of a chunk defined by its data.\n */\nfunction getChunkPath(chunkData: ChunkData): ChunkPath {\n  return typeof chunkData === \"string\" ? chunkData : chunkData.path;\n}\n\nfunction isPromise<T = any>(maybePromise: any): maybePromise is Promise<T> {\n  return (\n    maybePromise != null &&\n    typeof maybePromise === \"object\" &&\n    \"then\" in maybePromise &&\n    typeof maybePromise.then === \"function\"\n  );\n}\n\nfunction isAsyncModuleExt<T extends {}>(obj: T): obj is AsyncModuleExt & T {\n  return turbopackQueues in obj;\n}\n\nfunction createPromise<T>() {\n  let resolve: (value: T | PromiseLike<T>) => void;\n  let reject: (reason?: any) => void;\n\n  const promise = new Promise<T>((res, rej) => {\n    reject = rej;\n    resolve = res;\n  });\n\n  return {\n    promise,\n    resolve: resolve!,\n    reject: reject!,\n  };\n}\n\n// everything below is adapted from webpack\n// https://github.com/webpack/webpack/blob/6be4065ade1e252c1d8dcba4af0f43e32af1bdc1/lib/runtime/AsyncModuleRuntimeModule.js#L13\n\nconst turbopackQueues = Symbol(\"turbopack queues\");\nconst turbopackExports = Symbol(\"turbopack exports\");\nconst turbopackError = Symbol(\"turbopack error\");\n\ntype AsyncQueueFn = (() => void) & { queueCount: number };\ntype AsyncQueue = AsyncQueueFn[] & { resolved: boolean };\n\nfunction resolveQueue(queue?: AsyncQueue) {\n  if (queue && !queue.resolved) {\n    queue.resolved = true;\n    queue.forEach((fn) => fn.queueCount--);\n    queue.forEach((fn) => (fn.queueCount-- ? fn.queueCount++ : fn()));\n  }\n}\n\ntype Dep = Exports | AsyncModulePromise | Promise<Exports>;\n\ntype AsyncModuleExt = {\n  [turbopackQueues]: (fn: (queue: AsyncQueue) => void) => void;\n  [turbopackExports]: Exports;\n  [turbopackError]?: any;\n};\n\ntype AsyncModulePromise<T = Exports> = Promise<T> & AsyncModuleExt;\n\nfunction wrapDeps(deps: Dep[]): AsyncModuleExt[] {\n  return deps.map((dep) => {\n    if (dep !== null && typeof dep === \"object\") {\n      if (isAsyncModuleExt(dep)) return dep;\n      if (isPromise(dep)) {\n        const queue: AsyncQueue = Object.assign([], { resolved: false });\n\n        const obj: AsyncModuleExt = {\n          [turbopackExports]: {},\n          [turbopackQueues]: (fn: (queue: AsyncQueue) => void) => fn(queue),\n        };\n\n        dep.then(\n          (res) => {\n            obj[turbopackExports] = res;\n            resolveQueue(queue);\n          },\n          (err) => {\n            obj[turbopackError] = err;\n            resolveQueue(queue);\n          }\n        );\n\n        return obj;\n      }\n    }\n\n    const ret: AsyncModuleExt = {\n      [turbopackExports]: dep,\n      [turbopackQueues]: () => {},\n    };\n\n    return ret;\n  });\n}\n\nfunction asyncModule(\n  module: Module,\n  body: (\n    handleAsyncDependencies: (\n      deps: Dep[]\n    ) => Exports[] | Promise<() => Exports[]>,\n    asyncResult: (err?: any) => void\n  ) => void,\n  hasAwait: boolean\n) {\n  const queue: AsyncQueue | undefined = hasAwait\n    ? Object.assign([], { resolved: true })\n    : undefined;\n\n  const depQueues: Set<AsyncQueue> = new Set();\n\n  ensureDynamicExports(module, module.exports);\n  const exports = module.exports;\n\n  const { resolve, reject, promise: rawPromise } = createPromise<Exports>();\n\n  const promise: AsyncModulePromise = Object.assign(rawPromise, {\n    [turbopackExports]: exports,\n    [turbopackQueues]: (fn) => {\n      queue && fn(queue);\n      depQueues.forEach(fn);\n      promise[\"catch\"](() => {});\n    },\n  } satisfies AsyncModuleExt);\n\n  module.exports = module.namespaceObject = promise;\n\n  function handleAsyncDependencies(deps: Dep[]) {\n    const currentDeps = wrapDeps(deps);\n\n    const getResult = () =>\n      currentDeps.map((d) => {\n        if (d[turbopackError]) throw d[turbopackError];\n        return d[turbopackExports];\n      });\n\n    const { promise, resolve } = createPromise<() => Exports[]>();\n\n    const fn: AsyncQueueFn = Object.assign(() => resolve(getResult), {\n      queueCount: 0,\n    });\n\n    function fnQueue(q: AsyncQueue) {\n      if (q !== queue && !depQueues.has(q)) {\n        depQueues.add(q);\n        if (q && !q.resolved) {\n          fn.queueCount++;\n          q.push(fn);\n        }\n      }\n    }\n\n    currentDeps.map((dep) => dep[turbopackQueues](fnQueue));\n\n    return fn.queueCount ? promise : getResult();\n  }\n\n  function asyncResult(err?: any) {\n    if (err) {\n      reject((promise[turbopackError] = err));\n    } else {\n      resolve(exports);\n    }\n\n    resolveQueue(queue);\n  }\n\n  body(handleAsyncDependencies, asyncResult);\n\n  if (queue) {\n    queue.resolved = false;\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC,GAED,uDAAuD,GAEvD,6CAA6C;;AAU7C,MAAM,qBAAqB,OAAO;;;;;AA0ClC,MAAM,iBAAiB,OAAO,SAAS,CAAC,cAAc;AACtD,MAAM,cAAc,OAAO,WAAW,eAAe,OAAO,WAAW;AAEvE,SAAS,WACP,GAAQ,EACR,IAAiB,EACjB,OAA2C;IAE3C,IAAI,CAAC,eAAe,IAAI,CAAC,KAAK,OAC5B,OAAO,cAAc,CAAC,KAAK,MAAM;AACrC;AAEA;;CAEC,GACD,SAAS,IAAI,OAAgB,EAAE,OAAkC;IAC/D,WAAW,SAAS,cAAc;QAAE,OAAO;IAAK;IAChD,IAAI,aAAa,WAAW,SAAS,aAAa;QAAE,OAAO;IAAS;IACpE,IAAK,MAAM,OAAO,QAAS;QACzB,WAAW,SAAS,KAAK;YAAE,KAAK,OAAO,CAAC,IAAI;YAAE,YAAY;QAAK;IACjE;AACF;AAEA;;CAEC,GACD,SAAS,UACP,MAAc,EACd,OAAgB,EAChB,OAAkC;IAElC,OAAO,eAAe,GAAG,OAAO,OAAO;IACvC,IAAI,SAAS;AACf;AAEA,SAAS,qBAAqB,MAAc,EAAE,OAAgB;IAC5D,IAAI,oBAAoB,MAAM,CAAC,mBAAmB;IAElD,IAAI,CAAC,mBAAmB;QACtB,oBAAoB,MAAM,CAAC,mBAAmB,GAAG,EAAE;QACnD,OAAO,OAAO,GAAG,OAAO,eAAe,GAAG,IAAI,MAAM,SAAS;YAC3D,KAAI,MAAM,EAAE,IAAI;gBACd,IACE,eAAe,IAAI,CAAC,QAAQ,SAC5B,SAAS,aACT,SAAS,cACT;oBACA,OAAO,QAAQ,GAAG,CAAC,QAAQ;gBAC7B;gBACA,KAAK,MAAM,OAAO,kBAAoB;oBACpC,MAAM,QAAQ,QAAQ,GAAG,CAAC,KAAK;oBAC/B,IAAI,UAAU,WAAW,OAAO;gBAClC;gBACA,OAAO;YACT;YACA,SAAQ,MAAM;gBACZ,MAAM,OAAO,QAAQ,OAAO,CAAC;gBAC7B,KAAK,MAAM,OAAO,kBAAoB;oBACpC,KAAK,MAAM,OAAO,QAAQ,OAAO,CAAC,KAAM;wBACtC,IAAI,QAAQ,aAAa,CAAC,KAAK,QAAQ,CAAC,MAAM,KAAK,IAAI,CAAC;oBAC1D;gBACF;gBACA,OAAO;YACT;QACF;IACF;AACF;AAEA;;CAEC,GACD,SAAS,cACP,MAAc,EACd,OAAgB,EAChB,MAA2B;IAE3B,qBAAqB,QAAQ;IAE7B,MAAM,CAAC,mBAAmB,CAAE,IAAI,CAAC;AACnC;AAEA,SAAS,YAAY,MAAc,EAAE,KAAU;IAC7C,OAAO,OAAO,GAAG;AACnB;AAEA,SAAS,gBAAgB,MAAc,EAAE,SAAc;IACrD,OAAO,OAAO,GAAG,OAAO,eAAe,GAAG;AAC5C;AAEA,SAAS,aAAa,GAAiC,EAAE,GAAoB;IAC3E,OAAO,IAAM,GAAG,CAAC,IAAI;AACvB;AAEA;;CAEC,GACD,MAAM,WAA8B,OAAO,cAAc,GACrD,CAAC,MAAQ,OAAO,cAAc,CAAC,OAC/B,CAAC,MAAQ,IAAI,SAAS;AAE1B,iDAAiD,GACjD,MAAM,kBAAkB;IAAC;IAAM,SAAS,CAAC;IAAI,SAAS,EAAE;IAAG,SAAS;CAAU;AAE9E;;;;;;CAMC,GACD,SAAS,WACP,GAAY,EACZ,EAAsB,EACtB,kBAA4B;IAE5B,MAAM,UAAsC,OAAO,MAAM,CAAC;IAC1D,IACE,IAAI,UAAU,KACd,CAAC,OAAO,YAAY,YAAY,OAAO,YAAY,UAAU,KAC7D,CAAC,gBAAgB,QAAQ,CAAC,UAC1B,UAAU,SAAS,SACnB;QACA,KAAK,MAAM,OAAO,OAAO,mBAAmB,CAAC,SAAU;YACrD,OAAO,CAAC,IAAI,GAAG,aAAa,KAAK;QACnC;IACF;IAEA,6BAA6B;IAC7B,6EAA6E;IAC7E,IAAI,CAAC,CAAC,sBAAsB,aAAa,OAAO,GAAG;QACjD,OAAO,CAAC,UAAU,GAAG,IAAM;IAC7B;IAEA,IAAI,IAAI;IACR,OAAO;AACT;AAEA,SAAS,UACP,YAAoB,EACpB,EAAY;IAEZ,MAAM,SAAS,iCAAiC,IAAI;IACpD,IAAI,OAAO,KAAK,EAAE,MAAM,OAAO,KAAK;IAEpC,8DAA8D;IAC9D,IAAI,OAAO,eAAe,EAAE,OAAO,OAAO,eAAe;IAEzD,iGAAiG;IACjG,MAAM,MAAM,OAAO,OAAO;IAC1B,OAAQ,OAAO,eAAe,GAAG,WAC/B,KACA,CAAC,GACD,AAAC,IAAY,UAAU;AAE3B;AAEA,SAAS,gBAAgB,YAAoB,EAAE,EAAY;IACzD,MAAM,SAAS,iCAAiC,IAAI;IACpD,IAAI,OAAO,KAAK,EAAE,MAAM,OAAO,KAAK;IACpC,OAAO,OAAO,OAAO;AACvB;AAIA,SAAS,eACP,YAAoB,EACpB,GAAsB;IAEtB,SAAS,eAAe,EAAY;QAClC,MAAM,QAAQ,GAAG,CAAC,GAAG;QAErB,IAAI,CAAC,OAAO;YACV,MAAM,IAAI,MACR,CAAC,OAAO,EAAE,GAAG,8DAA8D,CAAC;QAEhF;QAEA,OAAO,uBAAuB,OAAO;IACvC;IAEA,eAAe,IAAI,GAAG;QACpB,OAAO,OAAO,IAAI,CAAC;IACrB;IAEA,eAAe,OAAO,GAAG,CAAC;QACxB,MAAM,QAAQ,GAAG,CAAC,GAAG;QAErB,IAAI,CAAC,OAAO;YACV,MAAM,IAAI,MACR,CAAC,OAAO,EAAE,GAAG,8DAA8D,CAAC;QAEhF;QAEA,OAAO,MAAM,EAAE;IACjB;IAEA,OAAO;AACT;AAEA;;CAEC,GACD,SAAS,aAAa,SAAoB;IACxC,OAAO,OAAO,cAAc,WAAW,YAAY,UAAU,IAAI;AACnE;AAEA,SAAS,UAAmB,YAAiB;IAC3C,OACE,gBAAgB,QAChB,OAAO,iBAAiB,YACxB,UAAU,gBACV,OAAO,aAAa,IAAI,KAAK;AAEjC;AAEA,SAAS,iBAA+B,GAAM;IAC5C,OAAO,mBAAmB;AAC5B;AAEA,SAAS;IACP,IAAI;IACJ,IAAI;IAEJ,MAAM,UAAU,IAAI,QAAW,CAAC,KAAK;QACnC,SAAS;QACT,UAAU;IACZ;IAEA,OAAO;QACL;QACA,SAAS;QACT,QAAQ;IACV;AACF;AAEA,2CAA2C;AAC3C,+HAA+H;AAE/H,MAAM,kBAAkB,OAAO;AAC/B,MAAM,mBAAmB,OAAO;AAChC,MAAM,iBAAiB,OAAO;AAK9B,SAAS,aAAa,KAAkB;IACtC,IAAI,SAAS,CAAC,MAAM,QAAQ,EAAE;QAC5B,MAAM,QAAQ,GAAG;QACjB,MAAM,OAAO,CAAC,CAAC,KAAO,GAAG,UAAU;QACnC,MAAM,OAAO,CAAC,CAAC,KAAQ,GAAG,UAAU,KAAK,GAAG,UAAU,KAAK;IAC7D;AACF;AAYA,SAAS,SAAS,IAAW;IAC3B,OAAO,KAAK,GAAG,CAAC,CAAC;QACf,IAAI,QAAQ,QAAQ,OAAO,QAAQ,UAAU;YAC3C,IAAI,iBAAiB,MAAM,OAAO;YAClC,IAAI,UAAU,MAAM;gBAClB,MAAM,QAAoB,OAAO,MAAM,CAAC,EAAE,EAAE;oBAAE,UAAU;gBAAM;gBAE9D,MAAM,MAAsB;oBAC1B,CAAC,iBAAiB,EAAE,CAAC;oBACrB,CAAC,gBAAgB,EAAE,CAAC,KAAoC,GAAG;gBAC7D;gBAEA,IAAI,IAAI,CACN,CAAC;oBACC,GAAG,CAAC,iBAAiB,GAAG;oBACxB,aAAa;gBACf,GACA,CAAC;oBACC,GAAG,CAAC,eAAe,GAAG;oBACtB,aAAa;gBACf;gBAGF,OAAO;YACT;QACF;QAEA,MAAM,MAAsB;YAC1B,CAAC,iBAAiB,EAAE;YACpB,CAAC,gBAAgB,EAAE,KAAO;QAC5B;QAEA,OAAO;IACT;AACF;AAEA,SAAS,YACP,MAAc,EACd,IAKS,EACT,QAAiB;IAEjB,MAAM,QAAgC,WAClC,OAAO,MAAM,CAAC,EAAE,EAAE;QAAE,UAAU;IAAK,KACnC;IAEJ,MAAM,YAA6B,IAAI;IAEvC,qBAAqB,QAAQ,OAAO,OAAO;IAC3C,MAAM,UAAU,OAAO,OAAO;IAE9B,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,SAAS,UAAU,EAAE,GAAG;IAEjD,MAAM,UAA8B,OAAO,MAAM,CAAC,YAAY;QAC5D,CAAC,iBAAiB,EAAE;QACpB,CAAC,gBAAgB,EAAE,CAAC;YAClB,SAAS,GAAG;YACZ,UAAU,OAAO,CAAC;YAClB,OAAO,CAAC,QAAQ,CAAC,KAAO;QAC1B;IACF;IAEA,OAAO,OAAO,GAAG,OAAO,eAAe,GAAG;IAE1C,SAAS,wBAAwB,IAAW;QAC1C,MAAM,cAAc,SAAS;QAE7B,MAAM,YAAY,IAChB,YAAY,GAAG,CAAC,CAAC;gBACf,IAAI,CAAC,CAAC,eAAe,EAAE,MAAM,CAAC,CAAC,eAAe;gBAC9C,OAAO,CAAC,CAAC,iBAAiB;YAC5B;QAEF,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,GAAG;QAE7B,MAAM,KAAmB,OAAO,MAAM,CAAC,IAAM,QAAQ,YAAY;YAC/D,YAAY;QACd;QAEA,SAAS,QAAQ,CAAa;YAC5B,IAAI,MAAM,SAAS,CAAC,UAAU,GAAG,CAAC,IAAI;gBACpC,UAAU,GAAG,CAAC;gBACd,IAAI,KAAK,CAAC,EAAE,QAAQ,EAAE;oBACpB,GAAG,UAAU;oBACb,EAAE,IAAI,CAAC;gBACT;YACF;QACF;QAEA,YAAY,GAAG,CAAC,CAAC,MAAQ,GAAG,CAAC,gBAAgB,CAAC;QAE9C,OAAO,GAAG,UAAU,GAAG,UAAU;IACnC;IAEA,SAAS,YAAY,GAAS;QAC5B,IAAI,KAAK;YACP,OAAQ,OAAO,CAAC,eAAe,GAAG;QACpC,OAAO;YACL,QAAQ;QACV;QAEA,aAAa;IACf;IAEA,KAAK,yBAAyB;IAE9B,IAAI,OAAO;QACT,MAAM,QAAQ,GAAG;IACnB;AACF"}},
    {"offset": {"line": 273, "column": 0}, "map": {"version":3,"sources":["/turbopack/[turbopack]/dev/runtime/base/runtime-base.ts"],"sourcesContent":["/**\n * This file contains runtime types and functions that are shared between all\n * Turbopack *development* ECMAScript runtimes.\n *\n * It will be appended to the runtime code of each runtime right after the\n * shared runtime utils.\n */\n\n/* eslint-disable @next/next/no-assign-module-variable */\n\n/// <reference path=\"../../../shared/runtime-utils.ts\" />\n/// <reference path=\"./globals.d.ts\" />\n/// <reference path=\"./protocol.d.ts\" />\n/// <reference path=\"./extensions.d.ts\" />\n\n// This file must not use `import` and `export` statements. Otherwise, it\n// becomes impossible to augment interfaces declared in `<reference>`d files\n// (e.g. `Module`). Hence, the need for `import()` here.\ntype RefreshRuntimeGlobals =\n  import(\"@next/react-refresh-utils/dist/runtime\").RefreshRuntimeGlobals;\n\ndeclare var CHUNK_BASE_PATH: string;\ndeclare var $RefreshHelpers$: RefreshRuntimeGlobals[\"$RefreshHelpers$\"];\ndeclare var $RefreshReg$: RefreshRuntimeGlobals[\"$RefreshReg$\"];\ndeclare var $RefreshSig$: RefreshRuntimeGlobals[\"$RefreshSig$\"];\ndeclare var $RefreshInterceptModuleExecution$:\n  | RefreshRuntimeGlobals[\"$RefreshInterceptModuleExecution$\"];\n\ntype RefreshContext = {\n  register: RefreshRuntimeGlobals[\"$RefreshReg$\"];\n  signature: RefreshRuntimeGlobals[\"$RefreshSig$\"];\n};\n\ntype RefreshHelpers = RefreshRuntimeGlobals[\"$RefreshHelpers$\"];\n\ninterface TurbopackDevBaseContext extends TurbopackBaseContext {\n  k: RefreshContext;\n}\n\ninterface TurbopackDevContext extends TurbopackDevBaseContext {}\n\n// string encoding of a module factory (used in hmr updates)\ntype ModuleFactoryString = string;\n\ntype ModuleFactory = (\n  this: Module[\"exports\"],\n  context: TurbopackDevContext\n) => undefined;\n\ntype DevRuntimeParams = {\n  otherChunks: ChunkData[];\n  runtimeModuleIds: ModuleId[];\n};\n\ntype ChunkRegistration = [\n  chunkPath: ChunkPath,\n  chunkModules: ModuleFactories,\n  params: DevRuntimeParams | undefined\n];\ntype ChunkList = {\n  path: ChunkPath;\n  chunks: ChunkData[];\n  source: \"entry\" | \"dynamic\";\n};\n\nenum SourceType {\n  /**\n   * The module was instantiated because it was included in an evaluated chunk's\n   * runtime.\n   */\n  Runtime = 0,\n  /**\n   * The module was instantiated because a parent module imported it.\n   */\n  Parent = 1,\n  /**\n   * The module was instantiated because it was included in a chunk's hot module\n   * update.\n   */\n  Update = 2,\n}\n\ntype SourceInfo =\n  | {\n      type: SourceType.Runtime;\n      chunkPath: ChunkPath;\n    }\n  | {\n      type: SourceType.Parent;\n      parentId: ModuleId;\n    }\n  | {\n      type: SourceType.Update;\n      parents?: ModuleId[];\n    };\n\ninterface RuntimeBackend {\n  registerChunk: (chunkPath: ChunkPath, params?: DevRuntimeParams) => void;\n  loadChunk: (chunkPath: ChunkPath, source: SourceInfo) => Promise<void>;\n  reloadChunk?: (chunkPath: ChunkPath) => Promise<void>;\n  unloadChunk?: (chunkPath: ChunkPath) => void;\n\n  restart: () => void;\n}\n\nconst moduleFactories: ModuleFactories = Object.create(null);\nconst moduleCache: ModuleCache = Object.create(null);\n/**\n * Maps module IDs to persisted data between executions of their hot module\n * implementation (`hot.data`).\n */\nconst moduleHotData: Map<ModuleId, HotData> = new Map();\n/**\n * Maps module instances to their hot module state.\n */\nconst moduleHotState: Map<Module, HotState> = new Map();\n/**\n * Modules that call `module.hot.invalidate()` (while being updated).\n */\nconst queuedInvalidatedModules: Set<ModuleId> = new Set();\n/**\n * Module IDs that are instantiated as part of the runtime of a chunk.\n */\nconst runtimeModules: Set<ModuleId> = new Set();\n/**\n * Map from module ID to the chunks that contain this module.\n *\n * In HMR, we need to keep track of which modules are contained in which so\n * chunks. This is so we don't eagerly dispose of a module when it is removed\n * from chunk A, but still exists in chunk B.\n */\nconst moduleChunksMap: Map<ModuleId, Set<ChunkPath>> = new Map();\n/**\n * Map from a chunk path to all modules it contains.\n */\nconst chunkModulesMap: Map<ModuleId, Set<ChunkPath>> = new Map();\n/**\n * Chunk lists that contain a runtime. When these chunk lists receive an update\n * that can't be reconciled with the current state of the page, we need to\n * reload the runtime entirely.\n */\nconst runtimeChunkLists: Set<ChunkPath> = new Set();\n/**\n * Map from a chunk list to the chunk paths it contains.\n */\nconst chunkListChunksMap: Map<ChunkPath, Set<ChunkPath>> = new Map();\n/**\n * Map from a chunk path to the chunk lists it belongs to.\n */\nconst chunkChunkListsMap: Map<ChunkPath, Set<ChunkPath>> = new Map();\n\nconst availableModules: Map<ModuleId, Promise<any> | true> = new Map();\n\nconst availableModuleChunks: Map<ChunkPath, Promise<any> | true> = new Map();\n\nasync function loadChunk(\n  source: SourceInfo,\n  chunkData: ChunkData\n): Promise<any> {\n  if (typeof chunkData === \"string\") {\n    return loadChunkPath(source, chunkData);\n  }\n\n  const includedList = chunkData.included || [];\n  const modulesPromises = includedList.map((included) => {\n    if (moduleFactories[included]) return true;\n    return availableModules.get(included);\n  });\n  if (modulesPromises.length > 0 && modulesPromises.every((p) => p)) {\n    // When all included items are already loaded or loading, we can skip loading ourselves\n    return Promise.all(modulesPromises);\n  }\n\n  const includedModuleChunksList = chunkData.moduleChunks || [];\n  const moduleChunksPromises = includedModuleChunksList\n    .map((included) => {\n      // TODO(alexkirsz) Do we need this check?\n      // if (moduleFactories[included]) return true;\n      return availableModuleChunks.get(included);\n    })\n    .filter((p) => p);\n\n  let promise;\n  if (moduleChunksPromises.length > 0) {\n    // Some module chunks are already loaded or loading.\n\n    if (moduleChunksPromises.length == includedModuleChunksList.length) {\n      // When all included module chunks are already loaded or loading, we can skip loading ourselves\n      return Promise.all(moduleChunksPromises);\n    }\n\n    const moduleChunksToLoad: Set<ChunkPath> = new Set();\n    for (const moduleChunk of includedModuleChunksList) {\n      if (!availableModuleChunks.has(moduleChunk)) {\n        moduleChunksToLoad.add(moduleChunk);\n      }\n    }\n\n    for (const moduleChunkToLoad of moduleChunksToLoad) {\n      const promise = loadChunkPath(source, moduleChunkToLoad);\n\n      availableModuleChunks.set(moduleChunkToLoad, promise);\n\n      moduleChunksPromises.push(promise);\n    }\n\n    promise = Promise.all(moduleChunksPromises);\n  } else {\n    promise = loadChunkPath(source, chunkData.path);\n\n    // Mark all included module chunks as loading if they are not already loaded or loading.\n    for (const includedModuleChunk of includedModuleChunksList) {\n      if (!availableModuleChunks.has(includedModuleChunk)) {\n        availableModuleChunks.set(includedModuleChunk, promise);\n      }\n    }\n  }\n\n  for (const included of includedList) {\n    if (!availableModules.has(included)) {\n      // It might be better to race old and new promises, but it's rare that the new promise will be faster than a request started earlier.\n      // In production it's even more rare, because the chunk optimization tries to deduplicate modules anyway.\n      availableModules.set(included, promise);\n    }\n  }\n\n  return promise;\n}\n\nasync function loadChunkPath(\n  source: SourceInfo,\n  chunkPath: ChunkPath\n): Promise<any> {\n  try {\n    await BACKEND.loadChunk(chunkPath, source);\n  } catch (error) {\n    let loadReason;\n    switch (source.type) {\n      case SourceType.Runtime:\n        loadReason = `as a runtime dependency of chunk ${source.chunkPath}`;\n        break;\n      case SourceType.Parent:\n        loadReason = `from module ${source.parentId}`;\n        break;\n      case SourceType.Update:\n        loadReason = \"from an HMR update\";\n        break;\n    }\n    throw new Error(\n      `Failed to load chunk ${chunkPath} ${loadReason}${\n        error ? `: ${error}` : \"\"\n      }`,\n      error\n        ? {\n            cause: error,\n          }\n        : undefined\n    );\n  }\n}\n\nfunction instantiateModule(id: ModuleId, source: SourceInfo): Module {\n  const moduleFactory = moduleFactories[id];\n  if (typeof moduleFactory !== \"function\") {\n    // This can happen if modules incorrectly handle HMR disposes/updates,\n    // e.g. when they keep a `setTimeout` around which still executes old code\n    // and contains e.g. a `require(\"something\")` call.\n    let instantiationReason;\n    switch (source.type) {\n      case SourceType.Runtime:\n        instantiationReason = `as a runtime entry of chunk ${source.chunkPath}`;\n        break;\n      case SourceType.Parent:\n        instantiationReason = `because it was required from module ${source.parentId}`;\n        break;\n      case SourceType.Update:\n        instantiationReason = \"because of an HMR update\";\n        break;\n    }\n    throw new Error(\n      `Module ${id} was instantiated ${instantiationReason}, but the module factory is not available. It might have been deleted in an HMR update.`\n    );\n  }\n\n  const hotData = moduleHotData.get(id)!;\n  const { hot, hotState } = createModuleHot(id, hotData);\n\n  let parents: ModuleId[];\n  switch (source.type) {\n    case SourceType.Runtime:\n      runtimeModules.add(id);\n      parents = [];\n      break;\n    case SourceType.Parent:\n      // No need to add this module as a child of the parent module here, this\n      // has already been taken care of in `getOrInstantiateModuleFromParent`.\n      parents = [source.parentId];\n      break;\n    case SourceType.Update:\n      parents = source.parents || [];\n      break;\n  }\n  const module: Module = {\n    exports: {},\n    error: undefined,\n    loaded: false,\n    id,\n    parents,\n    children: [],\n    namespaceObject: undefined,\n    hot,\n  };\n\n  moduleCache[id] = module;\n  moduleHotState.set(module, hotState);\n\n  // NOTE(alexkirsz) This can fail when the module encounters a runtime error.\n  try {\n    const sourceInfo: SourceInfo = { type: SourceType.Parent, parentId: id };\n\n    runModuleExecutionHooks(module, (refresh) => {\n      moduleFactory.call(\n        module.exports,\n        augmentContext({\n          a: asyncModule.bind(null, module),\n          e: module.exports,\n          r: commonJsRequire.bind(null, module),\n          f: requireContext.bind(null, module),\n          i: esmImport.bind(null, module),\n          s: esmExport.bind(null, module, module.exports),\n          j: dynamicExport.bind(null, module, module.exports),\n          v: exportValue.bind(null, module),\n          n: exportNamespace.bind(null, module),\n          m: module,\n          c: moduleCache,\n          l: loadChunk.bind(null, sourceInfo),\n          w: loadWebAssembly.bind(null, sourceInfo),\n          u: loadWebAssemblyModule.bind(null, sourceInfo),\n          g: globalThis,\n          k: refresh,\n          __dirname: module.id.replace(/(^|\\/)\\/+$/, \"\"),\n        })\n      );\n    });\n  } catch (error) {\n    module.error = error as any;\n    throw error;\n  }\n\n  module.loaded = true;\n  if (module.namespaceObject && module.exports !== module.namespaceObject) {\n    // in case of a circular dependency: cjs1 -> esm2 -> cjs1\n    interopEsm(module.exports, module.namespaceObject);\n  }\n\n  return module;\n}\n\n/**\n * NOTE(alexkirsz) Webpack has a \"module execution\" interception hook that\n * Next.js' React Refresh runtime hooks into to add module context to the\n * refresh registry.\n */\nfunction runModuleExecutionHooks(\n  module: Module,\n  executeModule: (ctx: RefreshContext) => void\n) {\n  const cleanupReactRefreshIntercept =\n    typeof globalThis.$RefreshInterceptModuleExecution$ === \"function\"\n      ? globalThis.$RefreshInterceptModuleExecution$(module.id)\n      : () => {};\n\n  try {\n    executeModule({\n      register: globalThis.$RefreshReg$,\n      signature: globalThis.$RefreshSig$,\n    });\n\n    if (\"$RefreshHelpers$\" in globalThis) {\n      // This pattern can also be used to register the exports of\n      // a module with the React Refresh runtime.\n      registerExportsAndSetupBoundaryForReactRefresh(\n        module,\n        globalThis.$RefreshHelpers$\n      );\n    }\n  } catch (e) {\n    throw e;\n  } finally {\n    // Always cleanup the intercept, even if module execution failed.\n    cleanupReactRefreshIntercept();\n  }\n}\n\n/**\n * Retrieves a module from the cache, or instantiate it if it is not cached.\n */\nconst getOrInstantiateModuleFromParent: GetOrInstantiateModuleFromParent = (\n  id,\n  sourceModule\n) => {\n  if (!sourceModule.hot.active) {\n    console.warn(\n      `Unexpected import of module ${id} from module ${sourceModule.id}, which was deleted by an HMR update`\n    );\n  }\n\n  const module = moduleCache[id];\n\n  if (sourceModule.children.indexOf(id) === -1) {\n    sourceModule.children.push(id);\n  }\n\n  if (module) {\n    if (module.parents.indexOf(sourceModule.id) === -1) {\n      module.parents.push(sourceModule.id);\n    }\n\n    return module;\n  }\n\n  return instantiateModule(id, {\n    type: SourceType.Parent,\n    parentId: sourceModule.id,\n  });\n};\n\n/**\n * This is adapted from https://github.com/vercel/next.js/blob/3466862d9dc9c8bb3131712134d38757b918d1c0/packages/react-refresh-utils/internal/ReactRefreshModule.runtime.ts\n */\nfunction registerExportsAndSetupBoundaryForReactRefresh(\n  module: Module,\n  helpers: RefreshHelpers\n) {\n  const currentExports = module.exports;\n  const prevExports = module.hot.data.prevExports ?? null;\n\n  helpers.registerExportsForReactRefresh(currentExports, module.id);\n\n  // A module can be accepted automatically based on its exports, e.g. when\n  // it is a Refresh Boundary.\n  if (helpers.isReactRefreshBoundary(currentExports)) {\n    // Save the previous exports on update, so we can compare the boundary\n    // signatures.\n    module.hot.dispose((data) => {\n      data.prevExports = currentExports;\n    });\n    // Unconditionally accept an update to this module, we'll check if it's\n    // still a Refresh Boundary later.\n    module.hot.accept();\n\n    // This field is set when the previous version of this module was a\n    // Refresh Boundary, letting us know we need to check for invalidation or\n    // enqueue an update.\n    if (prevExports !== null) {\n      // A boundary can become ineligible if its exports are incompatible\n      // with the previous exports.\n      //\n      // For example, if you add/remove/change exports, we'll want to\n      // re-execute the importing modules, and force those components to\n      // re-render. Similarly, if you convert a class component to a\n      // function, we want to invalidate the boundary.\n      if (\n        helpers.shouldInvalidateReactRefreshBoundary(\n          prevExports,\n          currentExports\n        )\n      ) {\n        module.hot.invalidate();\n      } else {\n        helpers.scheduleUpdate();\n      }\n    }\n  } else {\n    // Since we just executed the code for the module, it's possible that the\n    // new exports made it ineligible for being a boundary.\n    // We only care about the case when we were _previously_ a boundary,\n    // because we already accepted this update (accidental side effect).\n    const isNoLongerABoundary = prevExports !== null;\n    if (isNoLongerABoundary) {\n      module.hot.invalidate();\n    }\n  }\n}\n\nfunction formatDependencyChain(dependencyChain: ModuleId[]): string {\n  return `Dependency chain: ${dependencyChain.join(\" -> \")}`;\n}\n\nfunction computeOutdatedModules(\n  added: Map<ModuleId, EcmascriptModuleEntry | undefined>,\n  modified: Map<ModuleId, EcmascriptModuleEntry>\n): {\n  outdatedModules: Set<ModuleId>;\n  newModuleFactories: Map<ModuleId, ModuleFactory>;\n} {\n  const newModuleFactories = new Map<ModuleId, ModuleFactory>();\n\n  for (const [moduleId, entry] of added) {\n    if (entry != null) {\n      newModuleFactories.set(moduleId, _eval(entry));\n    }\n  }\n\n  const outdatedModules = computedInvalidatedModules(modified.keys());\n\n  for (const [moduleId, entry] of modified) {\n    newModuleFactories.set(moduleId, _eval(entry));\n  }\n\n  return { outdatedModules, newModuleFactories };\n}\n\nfunction computedInvalidatedModules(\n  invalidated: Iterable<ModuleId>\n): Set<ModuleId> {\n  const outdatedModules = new Set<ModuleId>();\n\n  for (const moduleId of invalidated) {\n    const effect = getAffectedModuleEffects(moduleId);\n\n    switch (effect.type) {\n      case \"unaccepted\":\n        throw new Error(\n          `cannot apply update: unaccepted module. ${formatDependencyChain(\n            effect.dependencyChain\n          )}.`\n        );\n      case \"self-declined\":\n        throw new Error(\n          `cannot apply update: self-declined module. ${formatDependencyChain(\n            effect.dependencyChain\n          )}.`\n        );\n      case \"accepted\":\n        for (const outdatedModuleId of effect.outdatedModules) {\n          outdatedModules.add(outdatedModuleId);\n        }\n        break;\n      // TODO(alexkirsz) Dependencies: handle dependencies effects.\n    }\n  }\n\n  return outdatedModules;\n}\n\nfunction computeOutdatedSelfAcceptedModules(\n  outdatedModules: Iterable<ModuleId>\n): { moduleId: ModuleId; errorHandler: true | Function }[] {\n  const outdatedSelfAcceptedModules = [];\n  for (const moduleId of outdatedModules) {\n    const module = moduleCache[moduleId];\n    const hotState = moduleHotState.get(module)!;\n    if (module && hotState.selfAccepted && !hotState.selfInvalidated) {\n      outdatedSelfAcceptedModules.push({\n        moduleId,\n        errorHandler: hotState.selfAccepted,\n      });\n    }\n  }\n  return outdatedSelfAcceptedModules;\n}\n\n/**\n * Adds, deletes, and moves modules between chunks. This must happen before the\n * dispose phase as it needs to know which modules were removed from all chunks,\n * which we can only compute *after* taking care of added and moved modules.\n */\nfunction updateChunksPhase(\n  chunksAddedModules: Map<ChunkPath, Set<ModuleId>>,\n  chunksDeletedModules: Map<ChunkPath, Set<ModuleId>>\n): { disposedModules: Set<ModuleId> } {\n  for (const [chunkPath, addedModuleIds] of chunksAddedModules) {\n    for (const moduleId of addedModuleIds) {\n      addModuleToChunk(moduleId, chunkPath);\n    }\n  }\n\n  const disposedModules: Set<ModuleId> = new Set();\n  for (const [chunkPath, addedModuleIds] of chunksDeletedModules) {\n    for (const moduleId of addedModuleIds) {\n      if (removeModuleFromChunk(moduleId, chunkPath)) {\n        disposedModules.add(moduleId);\n      }\n    }\n  }\n\n  return { disposedModules };\n}\n\nfunction disposePhase(\n  outdatedModules: Iterable<ModuleId>,\n  disposedModules: Iterable<ModuleId>\n): { outdatedModuleParents: Map<ModuleId, Array<ModuleId>> } {\n  for (const moduleId of outdatedModules) {\n    disposeModule(moduleId, \"replace\");\n  }\n\n  for (const moduleId of disposedModules) {\n    disposeModule(moduleId, \"clear\");\n  }\n\n  // Removing modules from the module cache is a separate step.\n  // We also want to keep track of previous parents of the outdated modules.\n  const outdatedModuleParents = new Map();\n  for (const moduleId of outdatedModules) {\n    const oldModule = moduleCache[moduleId];\n    outdatedModuleParents.set(moduleId, oldModule?.parents);\n    delete moduleCache[moduleId];\n  }\n\n  // TODO(alexkirsz) Dependencies: remove outdated dependency from module\n  // children.\n\n  return { outdatedModuleParents };\n}\n\n/**\n * Disposes of an instance of a module.\n *\n * Returns the persistent hot data that should be kept for the next module\n * instance.\n *\n * NOTE: mode = \"replace\" will not remove modules from the moduleCache.\n * This must be done in a separate step afterwards.\n * This is important because all modules need to be disposed to update the\n * parent/child relationships before they are actually removed from the moduleCache.\n * If this was done in this method, the following disposeModule calls won't find\n * the module from the module id in the cache.\n */\nfunction disposeModule(moduleId: ModuleId, mode: \"clear\" | \"replace\") {\n  const module = moduleCache[moduleId];\n  if (!module) {\n    return;\n  }\n\n  const hotState = moduleHotState.get(module)!;\n  const data = {};\n\n  // Run the `hot.dispose` handler, if any, passing in the persistent\n  // `hot.data` object.\n  for (const disposeHandler of hotState.disposeHandlers) {\n    disposeHandler(data);\n  }\n\n  // This used to warn in `getOrInstantiateModuleFromParent` when a disposed\n  // module is still importing other modules.\n  module.hot.active = false;\n\n  moduleHotState.delete(module);\n\n  // TODO(alexkirsz) Dependencies: delete the module from outdated deps.\n\n  // Remove the disposed module from its children's parent list.\n  // It will be added back once the module re-instantiates and imports its\n  // children again.\n  for (const childId of module.children) {\n    const child = moduleCache[childId];\n    if (!child) {\n      continue;\n    }\n\n    const idx = child.parents.indexOf(module.id);\n    if (idx >= 0) {\n      child.parents.splice(idx, 1);\n    }\n  }\n\n  switch (mode) {\n    case \"clear\":\n      delete moduleCache[module.id];\n      moduleHotData.delete(module.id);\n      break;\n    case \"replace\":\n      moduleHotData.set(module.id, data);\n      break;\n    default:\n      invariant(mode, (mode) => `invalid mode: ${mode}`);\n  }\n}\n\nfunction applyPhase(\n  outdatedSelfAcceptedModules: {\n    moduleId: ModuleId;\n    errorHandler: true | Function;\n  }[],\n  newModuleFactories: Map<ModuleId, ModuleFactory>,\n  outdatedModuleParents: Map<ModuleId, Array<ModuleId>>,\n  reportError: (err: any) => void\n) {\n  // Update module factories.\n  for (const [moduleId, factory] of newModuleFactories.entries()) {\n    moduleFactories[moduleId] = factory;\n  }\n\n  // TODO(alexkirsz) Run new runtime entries here.\n\n  // TODO(alexkirsz) Dependencies: call accept handlers for outdated deps.\n\n  // Re-instantiate all outdated self-accepted modules.\n  for (const { moduleId, errorHandler } of outdatedSelfAcceptedModules) {\n    try {\n      instantiateModule(moduleId, {\n        type: SourceType.Update,\n        parents: outdatedModuleParents.get(moduleId),\n      });\n    } catch (err) {\n      if (typeof errorHandler === \"function\") {\n        try {\n          errorHandler(err, { moduleId, module: moduleCache[moduleId] });\n        } catch (err2) {\n          reportError(err2);\n          reportError(err);\n        }\n      } else {\n        reportError(err);\n      }\n    }\n  }\n}\n\n/**\n * Utility function to ensure all variants of an enum are handled.\n */\nfunction invariant(never: never, computeMessage: (arg: any) => string): never {\n  throw new Error(`Invariant: ${computeMessage(never)}`);\n}\n\nfunction applyUpdate(chunkListPath: ChunkPath, update: PartialUpdate) {\n  switch (update.type) {\n    case \"ChunkListUpdate\":\n      applyChunkListUpdate(chunkListPath, update);\n      break;\n    default:\n      invariant(update, (update) => `Unknown update type: ${update.type}`);\n  }\n}\n\nfunction applyChunkListUpdate(\n  chunkListPath: ChunkPath,\n  update: ChunkListUpdate\n) {\n  if (update.merged != null) {\n    for (const merged of update.merged) {\n      switch (merged.type) {\n        case \"EcmascriptMergedUpdate\":\n          applyEcmascriptMergedUpdate(chunkListPath, merged);\n          break;\n        default:\n          invariant(merged, (merged) => `Unknown merged type: ${merged.type}`);\n      }\n    }\n  }\n\n  if (update.chunks != null) {\n    for (const [chunkPath, chunkUpdate] of Object.entries(update.chunks)) {\n      switch (chunkUpdate.type) {\n        case \"added\":\n          BACKEND.loadChunk(chunkPath, { type: SourceType.Update });\n          break;\n        case \"total\":\n          BACKEND.reloadChunk?.(chunkPath);\n          break;\n        case \"deleted\":\n          BACKEND.unloadChunk?.(chunkPath);\n          break;\n        case \"partial\":\n          invariant(\n            chunkUpdate.instruction,\n            (instruction) =>\n              `Unknown partial instruction: ${JSON.stringify(instruction)}.`\n          );\n        default:\n          invariant(\n            chunkUpdate,\n            (chunkUpdate) => `Unknown chunk update type: ${chunkUpdate.type}`\n          );\n      }\n    }\n  }\n}\n\nfunction applyEcmascriptMergedUpdate(\n  chunkPath: ChunkPath,\n  update: EcmascriptMergedUpdate\n) {\n  const { entries = {}, chunks = {} } = update;\n  const { added, modified, chunksAdded, chunksDeleted } = computeChangedModules(\n    entries,\n    chunks\n  );\n  const { outdatedModules, newModuleFactories } = computeOutdatedModules(\n    added,\n    modified\n  );\n  const { disposedModules } = updateChunksPhase(chunksAdded, chunksDeleted);\n\n  applyInternal(outdatedModules, disposedModules, newModuleFactories);\n}\n\nfunction applyInvalidatedModules(outdatedModules: Set<ModuleId>) {\n  if (queuedInvalidatedModules.size > 0) {\n    computedInvalidatedModules(queuedInvalidatedModules).forEach((moduleId) => {\n      outdatedModules.add(moduleId);\n    });\n\n    queuedInvalidatedModules.clear();\n  }\n\n  return outdatedModules;\n}\n\nfunction applyInternal(\n  outdatedModules: Set<ModuleId>,\n  disposedModules: Iterable<ModuleId>,\n  newModuleFactories: Map<ModuleId, ModuleFactory>\n) {\n  outdatedModules = applyInvalidatedModules(outdatedModules);\n\n  const outdatedSelfAcceptedModules =\n    computeOutdatedSelfAcceptedModules(outdatedModules);\n\n  const { outdatedModuleParents } = disposePhase(\n    outdatedModules,\n    disposedModules\n  );\n\n  // we want to continue on error and only throw the error after we tried applying all updates\n  let error: any;\n  function reportError(err: any) {\n    if (!error) error = err;\n  }\n\n  applyPhase(\n    outdatedSelfAcceptedModules,\n    newModuleFactories,\n    outdatedModuleParents,\n    reportError\n  );\n\n  if (error) {\n    throw error;\n  }\n\n  if (queuedInvalidatedModules.size > 0) {\n    applyInternal(new Set(), [], new Map());\n  }\n}\n\nfunction computeChangedModules(\n  entries: Record<ModuleId, EcmascriptModuleEntry>,\n  updates: Record<ChunkPath, EcmascriptMergedChunkUpdate>\n): {\n  added: Map<ModuleId, EcmascriptModuleEntry | undefined>;\n  modified: Map<ModuleId, EcmascriptModuleEntry>;\n  deleted: Set<ModuleId>;\n  chunksAdded: Map<ChunkPath, Set<ModuleId>>;\n  chunksDeleted: Map<ChunkPath, Set<ModuleId>>;\n} {\n  const chunksAdded = new Map();\n  const chunksDeleted = new Map();\n  const added: Map<ModuleId, EcmascriptModuleEntry> = new Map();\n  const modified = new Map();\n  const deleted: Set<ModuleId> = new Set();\n\n  for (const [chunkPath, mergedChunkUpdate] of Object.entries(updates)) {\n    switch (mergedChunkUpdate.type) {\n      case \"added\": {\n        const updateAdded = new Set(mergedChunkUpdate.modules);\n        for (const moduleId of updateAdded) {\n          added.set(moduleId, entries[moduleId]);\n        }\n        chunksAdded.set(chunkPath, updateAdded);\n        break;\n      }\n      case \"deleted\": {\n        // We could also use `mergedChunkUpdate.modules` here.\n        const updateDeleted = new Set(chunkModulesMap.get(chunkPath));\n        for (const moduleId of updateDeleted) {\n          deleted.add(moduleId);\n        }\n        chunksDeleted.set(chunkPath, updateDeleted);\n        break;\n      }\n      case \"partial\": {\n        const updateAdded = new Set(mergedChunkUpdate.added);\n        const updateDeleted = new Set(mergedChunkUpdate.deleted);\n        for (const moduleId of updateAdded) {\n          added.set(moduleId, entries[moduleId]);\n        }\n        for (const moduleId of updateDeleted) {\n          deleted.add(moduleId);\n        }\n        chunksAdded.set(chunkPath, updateAdded);\n        chunksDeleted.set(chunkPath, updateDeleted);\n        break;\n      }\n      default:\n        invariant(\n          mergedChunkUpdate,\n          (mergedChunkUpdate) =>\n            `Unknown merged chunk update type: ${mergedChunkUpdate.type}`\n        );\n    }\n  }\n\n  // If a module was added from one chunk and deleted from another in the same update,\n  // consider it to be modified, as it means the module was moved from one chunk to another\n  // AND has new code in a single update.\n  for (const moduleId of added.keys()) {\n    if (deleted.has(moduleId)) {\n      added.delete(moduleId);\n      deleted.delete(moduleId);\n    }\n  }\n\n  for (const [moduleId, entry] of Object.entries(entries)) {\n    // Modules that haven't been added to any chunk but have new code are considered\n    // to be modified.\n    // This needs to be under the previous loop, as we need it to get rid of modules\n    // that were added and deleted in the same update.\n    if (!added.has(moduleId)) {\n      modified.set(moduleId, entry);\n    }\n  }\n\n  return { added, deleted, modified, chunksAdded, chunksDeleted };\n}\n\ntype ModuleEffect =\n  | {\n      type: \"unaccepted\";\n      dependencyChain: ModuleId[];\n    }\n  | {\n      type: \"self-declined\";\n      dependencyChain: ModuleId[];\n      moduleId: ModuleId;\n    }\n  | {\n      type: \"accepted\";\n      moduleId: ModuleId;\n      outdatedModules: Set<ModuleId>;\n    };\n\nfunction getAffectedModuleEffects(moduleId: ModuleId): ModuleEffect {\n  const outdatedModules: Set<ModuleId> = new Set();\n\n  type QueueItem = { moduleId?: ModuleId; dependencyChain: ModuleId[] };\n\n  const queue: QueueItem[] = [\n    {\n      moduleId,\n      dependencyChain: [],\n    },\n  ];\n\n  let nextItem;\n  while ((nextItem = queue.shift())) {\n    const { moduleId, dependencyChain } = nextItem;\n\n    if (moduleId != null) {\n      outdatedModules.add(moduleId);\n    }\n\n    // We've arrived at the runtime of the chunk, which means that nothing\n    // else above can accept this update.\n    if (moduleId === undefined) {\n      return {\n        type: \"unaccepted\",\n        dependencyChain,\n      };\n    }\n\n    const module = moduleCache[moduleId];\n    const hotState = moduleHotState.get(module)!;\n\n    if (\n      // The module is not in the cache. Since this is a \"modified\" update,\n      // it means that the module was never instantiated before.\n      !module || // The module accepted itself without invalidating globalThis.\n      // TODO is that right?\n      (hotState.selfAccepted && !hotState.selfInvalidated)\n    ) {\n      continue;\n    }\n\n    if (hotState.selfDeclined) {\n      return {\n        type: \"self-declined\",\n        dependencyChain,\n        moduleId,\n      };\n    }\n\n    if (runtimeModules.has(moduleId)) {\n      queue.push({\n        moduleId: undefined,\n        dependencyChain: [...dependencyChain, moduleId],\n      });\n      continue;\n    }\n\n    for (const parentId of module.parents) {\n      const parent = moduleCache[parentId];\n\n      if (!parent) {\n        // TODO(alexkirsz) Is this even possible?\n        continue;\n      }\n\n      // TODO(alexkirsz) Dependencies: check accepted and declined\n      // dependencies here.\n\n      queue.push({\n        moduleId: parentId,\n        dependencyChain: [...dependencyChain, moduleId],\n      });\n    }\n  }\n\n  return {\n    type: \"accepted\",\n    moduleId,\n    outdatedModules,\n  };\n}\n\nfunction handleApply(chunkListPath: ChunkPath, update: ServerMessage) {\n  switch (update.type) {\n    case \"partial\": {\n      // This indicates that the update is can be applied to the current state of the application.\n      applyUpdate(chunkListPath, update.instruction);\n      break;\n    }\n    case \"restart\": {\n      // This indicates that there is no way to apply the update to the\n      // current state of the application, and that the application must be\n      // restarted.\n      BACKEND.restart();\n      break;\n    }\n    case \"notFound\": {\n      // This indicates that the chunk list no longer exists: either the dynamic import which created it was removed,\n      // or the page itself was deleted.\n      // If it is a dynamic import, we simply discard all modules that the chunk has exclusive access to.\n      // If it is a runtime chunk list, we restart the application.\n      if (runtimeChunkLists.has(chunkListPath)) {\n        BACKEND.restart();\n      } else {\n        disposeChunkList(chunkListPath);\n      }\n      break;\n    }\n    default:\n      throw new Error(`Unknown update type: ${update.type}`);\n  }\n}\n\nfunction createModuleHot(\n  moduleId: ModuleId,\n  hotData: HotData\n): { hot: Hot; hotState: HotState } {\n  const hotState: HotState = {\n    selfAccepted: false,\n    selfDeclined: false,\n    selfInvalidated: false,\n    disposeHandlers: [],\n  };\n\n  const hot: Hot = {\n    // TODO(alexkirsz) This is not defined in the HMR API. It was used to\n    // decide whether to warn whenever an HMR-disposed module required other\n    // modules. We might want to remove it.\n    active: true,\n\n    data: hotData ?? {},\n\n    // TODO(alexkirsz) Support full (dep, callback, errorHandler) form.\n    accept: (\n      modules?: string | string[] | AcceptErrorHandler,\n      _callback?: AcceptCallback,\n      _errorHandler?: AcceptErrorHandler\n    ) => {\n      if (modules === undefined) {\n        hotState.selfAccepted = true;\n      } else if (typeof modules === \"function\") {\n        hotState.selfAccepted = modules;\n      } else {\n        throw new Error(\"unsupported `accept` signature\");\n      }\n    },\n\n    decline: (dep) => {\n      if (dep === undefined) {\n        hotState.selfDeclined = true;\n      } else {\n        throw new Error(\"unsupported `decline` signature\");\n      }\n    },\n\n    dispose: (callback) => {\n      hotState.disposeHandlers.push(callback);\n    },\n\n    addDisposeHandler: (callback) => {\n      hotState.disposeHandlers.push(callback);\n    },\n\n    removeDisposeHandler: (callback) => {\n      const idx = hotState.disposeHandlers.indexOf(callback);\n      if (idx >= 0) {\n        hotState.disposeHandlers.splice(idx, 1);\n      }\n    },\n\n    invalidate: () => {\n      hotState.selfInvalidated = true;\n      queuedInvalidatedModules.add(moduleId);\n    },\n\n    // NOTE(alexkirsz) This is part of the management API, which we don't\n    // implement, but the Next.js React Refresh runtime uses this to decide\n    // whether to schedule an update.\n    status: () => \"idle\",\n\n    // NOTE(alexkirsz) Since we always return \"idle\" for now, these are no-ops.\n    addStatusHandler: (_handler) => {},\n    removeStatusHandler: (_handler) => {},\n\n    // NOTE(jridgewell) Check returns the list of updated modules, but we don't\n    // want the webpack code paths to ever update (the turbopack paths handle\n    // this already).\n    check: () => Promise.resolve(null),\n  };\n\n  return { hot, hotState };\n}\n\n/**\n * Adds a module to a chunk.\n */\nfunction addModuleToChunk(moduleId: ModuleId, chunkPath: ChunkPath) {\n  let moduleChunks = moduleChunksMap.get(moduleId);\n  if (!moduleChunks) {\n    moduleChunks = new Set([chunkPath]);\n    moduleChunksMap.set(moduleId, moduleChunks);\n  } else {\n    moduleChunks.add(chunkPath);\n  }\n\n  let chunkModules = chunkModulesMap.get(chunkPath);\n  if (!chunkModules) {\n    chunkModules = new Set([moduleId]);\n    chunkModulesMap.set(chunkPath, chunkModules);\n  } else {\n    chunkModules.add(moduleId);\n  }\n}\n\n/**\n * Returns the first chunk that included a module.\n * This is used by the Node.js backend, hence why it's marked as unused in this\n * file.\n */\nfunction getFirstModuleChunk(moduleId: ModuleId) {\n  const moduleChunkPaths = moduleChunksMap.get(moduleId);\n  if (moduleChunkPaths == null) {\n    return null;\n  }\n\n  return moduleChunkPaths.values().next().value;\n}\n\n/**\n * Removes a module from a chunk.\n * Returns `true` if there are no remaining chunks including this module.\n */\nfunction removeModuleFromChunk(\n  moduleId: ModuleId,\n  chunkPath: ChunkPath\n): boolean {\n  const moduleChunks = moduleChunksMap.get(moduleId)!;\n  moduleChunks.delete(chunkPath);\n\n  const chunkModules = chunkModulesMap.get(chunkPath)!;\n  chunkModules.delete(moduleId);\n\n  const noRemainingModules = chunkModules.size === 0;\n  if (noRemainingModules) {\n    chunkModulesMap.delete(chunkPath);\n  }\n\n  const noRemainingChunks = moduleChunks.size === 0;\n  if (noRemainingChunks) {\n    moduleChunksMap.delete(moduleId);\n  }\n\n  return noRemainingChunks;\n}\n\n/**\n * Disposes of a chunk list and its corresponding exclusive chunks.\n */\nfunction disposeChunkList(chunkListPath: ChunkPath): boolean {\n  const chunkPaths = chunkListChunksMap.get(chunkListPath);\n  if (chunkPaths == null) {\n    return false;\n  }\n  chunkListChunksMap.delete(chunkListPath);\n\n  for (const chunkPath of chunkPaths) {\n    const chunkChunkLists = chunkChunkListsMap.get(chunkPath)!;\n    chunkChunkLists.delete(chunkListPath);\n\n    if (chunkChunkLists.size === 0) {\n      chunkChunkListsMap.delete(chunkPath);\n      disposeChunk(chunkPath);\n    }\n  }\n\n  // We must also dispose of the chunk list's chunk itself to ensure it may\n  // be reloaded properly in the future.\n  BACKEND.unloadChunk?.(chunkListPath);\n\n  return true;\n}\n\n/**\n * Disposes of a chunk and its corresponding exclusive modules.\n *\n * @returns Whether the chunk was disposed of.\n */\nfunction disposeChunk(chunkPath: ChunkPath): boolean {\n  // This should happen whether the chunk has any modules in it or not.\n  // For instance, CSS chunks have no modules in them, but they still need to be unloaded.\n  BACKEND.unloadChunk?.(chunkPath);\n\n  const chunkModules = chunkModulesMap.get(chunkPath);\n  if (chunkModules == null) {\n    return false;\n  }\n  chunkModules.delete(chunkPath);\n\n  for (const moduleId of chunkModules) {\n    const moduleChunks = moduleChunksMap.get(moduleId)!;\n    moduleChunks.delete(chunkPath);\n\n    const noRemainingChunks = moduleChunks.size === 0;\n    if (noRemainingChunks) {\n      moduleChunksMap.delete(moduleId);\n      disposeModule(moduleId, \"clear\");\n      availableModules.delete(moduleId);\n    }\n  }\n\n  return true;\n}\n\n/**\n * Instantiates a runtime module.\n */\nfunction instantiateRuntimeModule(\n  moduleId: ModuleId,\n  chunkPath: ChunkPath\n): Module {\n  return instantiateModule(moduleId, { type: SourceType.Runtime, chunkPath });\n}\n\n/**\n * Gets or instantiates a runtime module.\n */\nfunction getOrInstantiateRuntimeModule(\n  moduleId: ModuleId,\n  chunkPath: ChunkPath\n): Module {\n  const module = moduleCache[moduleId];\n  if (module) {\n    if (module.error) {\n      throw module.error;\n    }\n    return module;\n  }\n\n  return instantiateModule(moduleId, { type: SourceType.Runtime, chunkPath });\n}\n\n/**\n * Returns the URL relative to the origin where a chunk can be fetched from.\n */\nfunction getChunkRelativeUrl(chunkPath: ChunkPath): string {\n  return `${CHUNK_BASE_PATH}${chunkPath}`;\n}\n\n/**\n * Subscribes to chunk list updates from the update server and applies them.\n */\nfunction registerChunkList(\n  chunkUpdateProvider: ChunkUpdateProvider,\n  chunkList: ChunkList\n) {\n  chunkUpdateProvider.push([\n    chunkList.path,\n    handleApply.bind(null, chunkList.path),\n  ]);\n\n  // Adding chunks to chunk lists and vice versa.\n  const chunks = new Set(chunkList.chunks.map(getChunkPath));\n  chunkListChunksMap.set(chunkList.path, chunks);\n  for (const chunkPath of chunks) {\n    let chunkChunkLists = chunkChunkListsMap.get(chunkPath);\n    if (!chunkChunkLists) {\n      chunkChunkLists = new Set([chunkList.path]);\n      chunkChunkListsMap.set(chunkPath, chunkChunkLists);\n    } else {\n      chunkChunkLists.add(chunkList.p