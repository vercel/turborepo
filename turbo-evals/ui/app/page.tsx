import Link from "next/link";
import { ArrowRight, Zap } from "lucide-react";

import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { ComparisonTable } from "@/components/comparison-table";

export default function Home() {
  return (
    <div className="flex flex-col min-h-screen">
      <header className="border-b">
        <div className="container mx-auto px-4 lg:px-6 h-16 flex items-center max-w-7xl">
          <Link className="flex items-center justify-center" href="#">
            <Zap className="h-6 w-6 text-primary" />
            <span className="ml-2 text-xl font-bold">ModelBench</span>
          </Link>
          <nav className="ml-auto flex gap-4 sm:gap-6">
            <Link
              className="text-sm font-medium hover:underline underline-offset-4"
              href="#"
            >
              About
            </Link>
            <Link
              className="text-sm font-medium hover:underline underline-offset-4"
              href="#methodology"
            >
              Methodology
            </Link>
            <Link
              className="text-sm font-medium hover:underline underline-offset-4"
              href="#"
            >
              Contact
            </Link>
          </nav>
        </div>
      </header>
      <main className="flex-1">
        <section className="w-full py-12 md:py-24 lg:py-32 bg-muted/40">
          <div className="container mx-auto px-4 md:px-6 max-w-7xl">
            <div className="flex flex-col items-center justify-center space-y-4 text-center">
              <div className="space-y-2">
                <h1 className="text-3xl font-bold tracking-tighter sm:text-5xl xl:text-6xl/none">
                  AI Model Performance on Next.js Code
                </h1>
                <p className="max-w-[600px] text-muted-foreground md:text-xl mx-auto">
                  Comprehensive benchmarks comparing how different AI models
                  perform across 31 different evaluations when operating on
                  Next.js code.
                </p>
              </div>
              <div className="flex flex-col gap-2 min-[400px]:flex-row justify-center">
                <Button className="inline-flex h-10 items-center justify-center px-8">
                  View Benchmarks
                  <ArrowRight className="ml-2 h-4 w-4" />
                </Button>
                <Button
                  variant="outline"
                  className="inline-flex h-10 items-center justify-center px-8 bg-transparent"
                >
                  Learn More
                </Button>
              </div>
            </div>
          </div>
        </section>
        <section className="w-full py-12 md:py-24 lg:py-32">
          <div className="container mx-auto px-4 md:px-6 max-w-7xl">
            <div className="flex flex-col items-center justify-center space-y-4 text-center">
              <div className="space-y-2">
                <h2 className="text-3xl font-bold tracking-tight sm:text-4xl">
                  Model Performance Comparison
                </h2>
                <p className="max-w-[900px] text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed mx-auto">
                  Compare how different AI models perform across 31 different
                  evaluations when working with Next.js code. Our benchmarks
                  measure execution time, token usage, and accuracy for specific
                  Next.js tasks.
                </p>
              </div>
            </div>
            <div className="mx-auto mt-8 w-full overflow-auto">
              <ComparisonTable />
            </div>
          </div>
        </section>
        <section
          className="w-full py-12 md:py-24 lg:py-32 bg-muted/40"
          id="methodology"
        >
          <div className="container mx-auto px-4 md:px-6 max-w-7xl">
            <div className="flex flex-col items-center justify-center space-y-4 text-center">
              <div className="space-y-2">
                <h2 className="text-3xl font-bold tracking-tight sm:text-4xl">
                  Methodology
                </h2>
                <p className="max-w-[900px] text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed mx-auto">
                  Our evaluation framework provides a comprehensive and fair
                  comparison of AI models on Next.js development tasks.
                </p>
              </div>
            </div>
            <div className="mt-8 grid gap-8 md:grid-cols-2 lg:grid-cols-3">
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">Evaluation Tasks</h3>
                  <p className="text-sm text-muted-foreground">
                    We test 31 different Next.js tasks including routing, server
                    components, client components, API routes, data fetching,
                    state management, and more. Each task represents a
                    real-world development scenario.
                  </p>
                </CardContent>
              </Card>
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">
                    Performance Metrics
                  </h3>
                  <p className="text-sm text-muted-foreground">
                    We measure evaluation score (accuracy), execution duration,
                    and token usage (prompt, completion, and total). These
                    metrics provide insights into both effectiveness and
                    efficiency of each model.
                  </p>
                </CardContent>
              </Card>
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">Fair Comparison</h3>
                  <p className="text-sm text-muted-foreground">
                    All models receive identical prompts and are evaluated using
                    the same criteria. Results are compared against a baseline
                    to identify improvements and regressions across different
                    tasks.
                  </p>
                </CardContent>
              </Card>
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">
                    Evaluation Environment
                  </h3>
                  <p className="text-sm text-muted-foreground">
                    Tests are run in isolated environments to ensure
                    consistency. Each evaluation is executed with the same
                    system resources and timeout constraints to maintain
                    fairness.
                  </p>
                </CardContent>
              </Card>
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">Scoring System</h3>
                  <p className="text-sm text-muted-foreground">
                    Evaluation scores range from 0 to 1, where 1 indicates
                    perfect performance. Scores are calculated based on
                    successful task completion, code quality, and adherence to
                    Next.js best practices.
                  </p>
                </CardContent>
              </Card>
              <Card>
                <CardContent className="p-6">
                  <h3 className="font-bold text-lg mb-2">Continuous Updates</h3>
                  <p className="text-sm text-muted-foreground">
                    Our benchmarks are regularly updated as new model versions
                    are released. This ensures the data remains relevant and
                    reflects the current state of AI model capabilities.
                  </p>
                </CardContent>
              </Card>
            </div>
          </div>
        </section>
      </main>
      <footer className="border-t">
        <div className="container mx-auto px-4 md:px-6 max-w-7xl flex flex-col gap-2 sm:flex-row py-6">
          <p className="text-xs text-muted-foreground">
            Â© 2025 ModelBench. All rights reserved.
          </p>
          <nav className="sm:ml-auto flex gap-4 sm:gap-6">
            <Link
              className="text-xs hover:underline underline-offset-4"
              href="#"
            >
              Terms of Service
            </Link>
            <Link
              className="text-xs hover:underline underline-offset-4"
              href="#"
            >
              Privacy
            </Link>
          </nav>
        </div>
      </footer>
    </div>
  );
}
